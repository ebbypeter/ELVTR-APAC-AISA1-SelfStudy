{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0ef3f0",
   "metadata": {},
   "source": [
    "# RAG (Retrieval-Augmented Generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd7862",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "All the environment variables, APIS keys etc are loaded in the `.env` file. Load it into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83052b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️  Loaded environment variables from .env file\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ℹ️  Loaded environment variables from .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5df2ed",
   "metadata": {},
   "source": [
    "## Preparing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "948e404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebby/05-src/personal/gh-ebbypeter/ELVTR-APAC-AISA1-SelfStudy/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Created a chunk of size 542, which is longer than the specified 512\n",
      "Created a chunk of size 622, which is longer than the specified 512\n",
      "Created a chunk of size 662, which is longer than the specified 512\n",
      "Created a chunk of size 632, which is longer than the specified 512\n",
      "Created a chunk of size 604, which is longer than the specified 512\n",
      "Created a chunk of size 542, which is longer than the specified 512\n",
      "Created a chunk of size 521, which is longer than the specified 512\n",
      "Created a chunk of size 519, which is longer than the specified 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️  Preparing Documents...\n",
      "  => Loading Artificial-Intelligence.md...\n",
      "  => Loading Deep-Learning.md...\n",
      "  => Loading Machine-Learning.md...\n",
      "  => Loading Python.md...\n",
      "  => Loading Cloud-Computing.md...\n",
      "  => Loading Web-Development.md...\n",
      "✅  Loaded and split documents into 22 chunks.\n",
      "✅  Sample chunk content:\n",
      "## Artificial Intelligence...\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "print(\"ℹ️  Preparing Documents...\")\n",
    "# Function to load markdown file content\n",
    "def load_markdown_file(filename):\n",
    "    \"\"\"Reads a markdown file and returns its content as a string.\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filename}' was not found.\")\n",
    "        return None\n",
    "    except IOError as e:\n",
    "        print(f\"Error reading file '{filename}': {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while reading '{filename}': {e}\")\n",
    "        return None\n",
    "    \n",
    "# Split the text into chunks\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=512, \n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "print(\"  => Loading Artificial-Intelligence.md...\")\n",
    "chunks.extend(text_splitter.split_text(load_markdown_file('./documents/Artificial-Intelligence.md')))\n",
    "print(\"  => Loading Deep-Learning.md...\")\n",
    "chunks.extend(text_splitter.split_text(load_markdown_file('./documents/Deep-Learning.md')))\n",
    "print(\"  => Loading Machine-Learning.md...\")\n",
    "chunks.extend(text_splitter.split_text(load_markdown_file('./documents/Machine-Learning.md')))\n",
    "print(\"  => Loading Python.md...\")\n",
    "chunks.extend(text_splitter.split_text(load_markdown_file('./documents/Python.md')))\n",
    "print(\"  => Loading Cloud-Computing.md...\")\n",
    "chunks.extend(text_splitter.split_text(load_markdown_file('./documents/Cloud-Computing.md')))\n",
    "print(\"  => Loading Web-Development.md...\")\n",
    "chunks.extend(text_splitter.split_text(load_markdown_file('./documents/Web-Development.md')))\n",
    "\n",
    "print(f\"✅  Loaded and split documents into {len(chunks)} chunks.\")\n",
    "print(f\"✅  Sample chunk content:\\n{chunks[0][:128]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef99ca",
   "metadata": {},
   "source": [
    "## Create Embeddings & Store in Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1811c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️  Creating Embeddings and Vector Stores...\n",
      "✅  Created vector store with embeddings.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "print(\"ℹ️  Creating Embeddings and Vector Stores...\")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "vector_store = Chroma.from_texts(\n",
    "    texts=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"knowledge_base\"\n",
    ")\n",
    "print(\"✅  Created vector store with embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88285996",
   "metadata": {},
   "source": [
    "## Create a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0834a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Configured retriever for similarity search.\n",
      "ℹ️  Testing retriever with a sample query...\n",
      "Query: 'What is deep learning?'\n",
      "✅  Retrieved 3 relevant chunks.\n",
      "Retrieved Documents:\n",
      "  1. ## Deep Learning...\n",
      "  2. Deep learning is a subfield of machine learning that uses multilayer artificial neural networks to learn hierarchical representations of data. The “deep” in deep learning refers to networks with many layers (often dozens or more), which successively transform raw inputs into increasingly abstract features. These architectures excel at modeling complex, non‑linear relationships in high‑dimensional data such as images, audio, and text. [en.wikipedia](https://en.wikipedia.org/wiki/Deep_learning)...\n",
      "  3. Deep learning has driven breakthroughs in image classification, speech recognition, natural language processing, recommendation, and generative media. The trade‑offs are high data requirements, significant computational cost (often GPUs or specialized accelerators), and reduced interpretability compared with simpler models. You use deep learning when the signal is rich and complex enough that manual feature engineering and shallow models hit a ceiling. [en.wikipedia](https://en.wikipedia.org/wiki/Artificial_intelligence)...\n"
     ]
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "print(\"✅  Configured retriever for similarity search.\")\n",
    "\n",
    "print(\"ℹ️  Testing retriever with a sample query...\")\n",
    "query = \"What is deep learning?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(f\"✅  Retrieved {len(retrieved_docs)} relevant chunks.\")\n",
    "print(\"Retrieved Documents:\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"  {i+1}. {doc.page_content}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f7701",
   "metadata": {},
   "source": [
    "## Build a RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d252b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️  OpenAI client initialized successfully with GPT-4o mode\n",
      "\n",
      "Testing RAG System:\n",
      "============================================================\n",
      "\n",
      "Question: Explain machine learning in simple terms\n",
      "\n",
      "Answer: Machine learning is a type of artificial intelligence where computers learn from data to make predictions or decisions without being specifically programmed for each task. It works by identifying patterns in data and creating a model that can generalize to new, unseen situations. This allows applications like spam email detection, demand forecasting, and credit scoring to improve over time as they process more information.\n",
      "Sources used: 1580 document(s)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Question: What is deep learning used for?\n",
      "\n",
      "Answer: Deep learning is used for breakthroughs in image classification, speech recognition, natural language processing, recommendation, and generative media.\n",
      "Sources used: 1043 document(s)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Question: Tell me about Python\n",
      "\n",
      "Answer: Python is a high-level, general-purpose programming language created by Guido van Rossum and first released in 1991. It emphasizes readability with a clean, English-like syntax and uses indentation instead of braces to define blocks. Python is versatile and runs on all major platforms, including Windows, macOS, Linux, and Raspberry Pi. It supports multiple programming paradigms, such as procedural, object-oriented, and functional programming.\n",
      "\n",
      "Python is known for its speed of development, rich ecosystem, and low barrier to entry. It is widely used for web development, scripting, automation, data analysis, machine learning, and system tools. Its standard library covers various functionalities like file I/O, networking, and concurrency, reducing the need for external packages for common tasks.\n",
      "\n",
      "The Python ecosystem includes popular libraries and frameworks such as Django and Flask for web applications, NumPy and Pandas for numerical computing and data manipulation, and Matplotlib for data visualization. In the field of machine learning and AI, Python is dominant with frameworks like scikit-learn, TensorFlow, and PyTorch. However, Python's runtime performance may not match lower-level languages like C++ or Rust, particularly in very large codebases or scenarios with stringent latency or memory constraints.\n",
      "Sources used: 1532 document(s)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Question: What is Quantum Mechanics?\n",
      "\n",
      "Answer: I don't have that information.\n",
      "Sources used: 540 document(s)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Use the following retrieved documents to answer the question. If the documents do not contain the answer, say \"I don't have that information\". \n",
    "    Be concise and accurate.\n",
    "    \n",
    "    Documents:\n",
    "    {retrieved_docs}\n",
    "    \n",
    "    Question:\n",
    "    {question}\n",
    "    \n",
    "    Answer:\n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "agent_openai_gpt4o = ChatOpenAI(\n",
    "    name=\"OpenAI GPT-4o\",\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.5,\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    organization=os.getenv('OPENAI_ORG_ID') if os.getenv('OPENAI_ORG_ID') else None\n",
    ") \n",
    "print(\"ℹ️  OpenAI client initialized successfully with GPT-4o mode\")\n",
    "\n",
    "# Create the RAG chain:\n",
    "def rag_chain(question):\n",
    "    \"\"\"Given a question, retrieve relevant documents and generate an answer using the LLM.\"\"\"\n",
    "    # Step 1: Retrieve relevant documents\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    \n",
    "    # Step 2: Format the retrieved documents into the prompt\n",
    "    formatted_docs = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    #prompt = rag_prompt.format(retrieved_docs=formatted_docs, question=question)\n",
    "    \n",
    "    # Step 3: Pass the prompt to the LLM for answer generation\n",
    "    response = rag_prompt | agent_openai_gpt4o\n",
    "    answer = response.invoke({\n",
    "        \"retrieved_docs\":formatted_docs, \n",
    "        \"question\":question\n",
    "    })\n",
    "    \n",
    "    return answer.content.strip(), formatted_docs\n",
    "\n",
    "# Test the RAG system\n",
    "print(\"\\nTesting RAG System:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_questions = [\n",
    "    \"Explain machine learning in simple terms\",\n",
    "    \"What is deep learning used for?\",\n",
    "    \"Tell me about Python\",\n",
    "    \"What is Quantum Mechanics?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    print(f\"\\nQuestion: {q}\")\n",
    "    answer, sources = rag_chain(q)\n",
    "    print(f\"\\nAnswer: {answer}\")\n",
    "    print(f\"Sources used: {len(sources)} document(s)\")\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
