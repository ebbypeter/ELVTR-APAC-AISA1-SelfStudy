{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447ef48f",
   "metadata": {},
   "source": [
    "# Assignment 03 - Basic RAG Architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46df295",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "All the environment variables, APIS keys etc are loaded in the `.env` file. Load it into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36318d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸  Loaded environment variables from .env file\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"â„¹ï¸  Loaded environment variables from .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5613f",
   "metadata": {},
   "source": [
    "## Define Data Sources\n",
    "\n",
    "Real Meta PDFs from their Investor Relations website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644ce3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data sources loaded!\n",
      "\n",
      "Available quarters: Q1, Q2, Q3, Q4\n",
      "Document types per quarter: press_release, presentation, earnings_call, followup_qa\n",
      "\n",
      "Total documents to process: 16 PDFs\n"
     ]
    }
   ],
   "source": [
    "# Real Meta earnings data sources\n",
    "data_sources = {\n",
    "    \"Q1\": {\n",
    "        \"press_release\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q1/Meta-03-31-2025-Exhibit-99-1-Final.pdf\",\n",
    "        \"presentation\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q1/Earnings-Presentation-Q1-2025-FINAL.pdf\",\n",
    "        \"earnings_call\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q1/Transcripts/META-Q1-2025-Earnings-Call-Transcript-1.pdf\",\n",
    "        \"followup_qa\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q1/Transcripts/META-Q1-2025-Follow-Up-Call-Transcript.pdf\"\n",
    "    },\n",
    "    \"Q2\": {\n",
    "        \"press_release\": \"https://s21.q4cdn.com/399680738/files/doc_downloads/Meta-06-30-2025-Exhibit-99-1-FINAL.pdf\",\n",
    "        \"presentation\": \"https://s21.q4cdn.com/399680738/files/doc_downloads/Earnings-Presentation-Q2-2025-FINAL.pdf\",\n",
    "        \"earnings_call\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q2/META-Q2-2025-Earnings-Call-Transcript.pdf\",\n",
    "        \"followup_qa\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q2/META-Q2-2025-Follow-Up-Call-Transcript.pdf\"\n",
    "    },\n",
    "    \"Q3\": {\n",
    "        \"press_release\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q3/Meta-09-30-2025-Exhibit-99-1-Final.pdf\",\n",
    "        \"presentation\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q3/Earnings-Presentation-Q3-2025-Final.pdf\",\n",
    "        \"earnings_call\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q3/META-Q3-2025-Earnings-Call-Transcript.pdf\",\n",
    "        \"followup_qa\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q3/META-Q3-2025-Follow-Up-Call-Transcript.pdf\"\n",
    "    },\n",
    "    \"Q4\": {\n",
    "        \"press_release\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q4/Meta-12-31-2025-Exhibit-99-1-FINAL.pdf\",\n",
    "        \"presentation\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q4/Earnings-Presentation-Q4-2025-FINAL.pdf\",\n",
    "        \"earnings_call\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q4/META-Q4-2025-Earnings-Call-Transcript.pdf\",\n",
    "        \"followup_qa\": \"https://s21.q4cdn.com/399680738/files/doc_financials/2025/q4/META-Q4-2025-Follow-Up-Call-Transcript.pdf\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… Data sources loaded!\")\n",
    "print()\n",
    "print(\"Available quarters: Q1, Q2, Q3, Q4\")\n",
    "print(\"Document types per quarter: press_release, presentation, earnings_call, followup_qa\")\n",
    "print()\n",
    "print(f\"Total documents to process: {len(data_sources) * 4} PDFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf4f71",
   "metadata": {},
   "source": [
    "## Initialize Wrappers\n",
    "\n",
    "Initialize the LLM Wrappers / Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b18465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import chromadb\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Initialize ChromaDB client (in-memory database, no API keys needed)\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4976dd",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Helper functions for PDF fetching and chunk storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36cae9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Utility functions defined!\n",
      "\n",
      "Functions available:\n",
      "  - fetch_and_extract_pdf(url): Fetch and extract text from PDFs\n",
      "  - fetch_and_extract_section_from_pdf(url): Extract sections from PDFs using PyMuPDF\n",
      "  - add_chunk_to_collection(): Add chunks to a collection\n",
      "  - query_collection(): Query a collection\n",
      "  - generate_rag_answer(): Generate LLM answers from chunks using GPT-4o\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def fetch_and_extract_pdf(pdf_url, timeout=10, return_type=\"Text\"):\n",
    "    \"\"\"\n",
    "    Fetch a PDF from a URL and extract all text\n",
    "    \n",
    "    Args:\n",
    "        pdf_url: URL to the PDF file\n",
    "        timeout: Request timeout in seconds\n",
    "        return_pages: If True, return list of pages; if False, return combined text\n",
    "    \n",
    "    Returns:\n",
    "        If return_pages=False: Extracted text (string) or None if error\n",
    "        If return_pages=True: List of page texts or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(pdf_url, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        pdf_file = BytesIO(response.content)\n",
    "        reader = PdfReader(pdf_file)\n",
    "        \n",
    "        if return_type == \"Pages\":\n",
    "            pages = []\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text and page_text.strip():\n",
    "                    pages.append(page_text.strip())\n",
    "            return pages if pages else None\n",
    "        elif return_type == \"Paragraphs\":\n",
    "            paragraphs = []\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    for para in page_text.split(\"\\n\\n\"):\n",
    "                        if para.strip():\n",
    "                            paragraphs.append(para.strip())\n",
    "            return paragraphs if paragraphs else None\n",
    "        else: # Text\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "            \n",
    "            return text.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Error fetching PDF: {str(e)[:60]}\")\n",
    "        return None\n",
    "\n",
    "def fetch_and_extract_section_from_pdf(pdf_url, timeout=10):\n",
    "    \"\"\"\n",
    "    Fetch a PDF from a URL and extract a specific section using PyMuPDF\n",
    "    \n",
    "    Args:\n",
    "        pdf_url: URL to the PDF file\n",
    "        timeout: Request timeout in seconds\n",
    "    \n",
    "    Returns:\n",
    "        Extracted section text (string) or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(stream=requests.get(pdf_url, timeout=timeout).content, filetype=\"pdf\")\n",
    "        sections = []\n",
    "        current_section = None\n",
    "        \n",
    "        for page_num, page in enumerate(doc):\n",
    "             blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "             \n",
    "             for block in blocks:\n",
    "                if \"lines\" not in block:\n",
    "                    continue\n",
    "                \n",
    "                for line in block[\"lines\"]:\n",
    "                    line_text = \"\"\n",
    "                    max_font_size = 0\n",
    "                    is_bold = False\n",
    "                    \n",
    "                    for span in line[\"spans\"]:\n",
    "                        for span in line[\"spans\"]:\n",
    "                            text = span[\"text\"].strip()\n",
    "                            if not text:\n",
    "                                continue\n",
    "                            \n",
    "                            line_text += text + \" \"\n",
    "                            font_size = span[\"size\"]\n",
    "                            max_font_size = max(max_font_size, font_size)\n",
    "                            \n",
    "                            if \"bold\" in span[\"font\"].lower():\n",
    "                                is_bold = True\n",
    "                        line_text = line_text.strip()\n",
    "                        \n",
    "                    # Detect section headings (adjust threshold based on your PDF)\n",
    "                    if max_font_size > 11 or is_bold or line_text.isupper():\n",
    "                        # Check if it's actually a heading (not too long)\n",
    "                        if len(line_text) < 100 and line_text:\n",
    "                            # Save previous section\n",
    "                            if current_section and current_section[\"content\"].strip():\n",
    "                                sections.append(current_section)\n",
    "                            \n",
    "                            # Start new section\n",
    "                            current_section = {\n",
    "                                \"title\": line_text,\n",
    "                                \"content\": \"\",\n",
    "                                \"page_start\": page_num + 1,\n",
    "                                \"font_size\": max_font_size\n",
    "                            }\n",
    "                    elif current_section:\n",
    "                        current_section[\"content\"] += line_text + \"\\n\"   \n",
    "                        \n",
    "        # Add last section\n",
    "        if current_section and current_section[\"content\"].strip():\n",
    "            sections.append(current_section)\n",
    "            \n",
    "        return sections if sections else None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Error fetching PDF section: {str(e)[:60]}\")\n",
    "        return None\n",
    "\n",
    "def add_chunk_to_collection(collection, doc_type, quarter, chunk_text, chunk_id):\n",
    "    \"\"\"\n",
    "    Add a text chunk to a ChromaDB collection\n",
    "    \n",
    "    Args:\n",
    "        collection: ChromaDB collection object\n",
    "        doc_type: Type of document (e.g., 'earnings_call')\n",
    "        quarter: Quarter (Q1, Q2, Q3)\n",
    "        chunk_text: The text content of the chunk\n",
    "        chunk_id: Unique identifier for the chunk\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        \"doc_type\": doc_type,\n",
    "        \"quarter\": quarter,\n",
    "        \"chunk_length\": len(chunk_text)\n",
    "    }\n",
    "    \n",
    "    collection.add(\n",
    "        ids=[chunk_id],\n",
    "        documents=[chunk_text],\n",
    "        metadatas=[metadata]\n",
    "    )\n",
    "\n",
    "def query_collection(collection, doc_type=None, quarter=None):\n",
    "    \"\"\"\n",
    "    Query a ChromaDB collection with optional filters\n",
    "    \n",
    "    Args:\n",
    "        collection: ChromaDB collection object\n",
    "        doc_type: Optional filter by document type\n",
    "        quarter: Optional filter by quarter\n",
    "    \n",
    "    Returns:\n",
    "        Query results dict with 'documents', 'metadatas', 'ids'\n",
    "    \"\"\"\n",
    "    where_filter = None\n",
    "    conditions = []\n",
    "    \n",
    "    if doc_type:\n",
    "        conditions.append({\"doc_type\": {\"$eq\": doc_type}})\n",
    "    if quarter:\n",
    "        conditions.append({\"quarter\": {\"$eq\": quarter}})\n",
    "    \n",
    "    if conditions:\n",
    "        if len(conditions) == 1:\n",
    "            where_filter = conditions[0]\n",
    "        else:\n",
    "            where_filter = {\"$and\": conditions}\n",
    "    \n",
    "    return collection.get(where=where_filter)\n",
    "\n",
    "def generate_rag_answer(query, chunks, max_chunks=15):\n",
    "    \"\"\"\n",
    "    Generate an answer using GPT-4o based on a query and retrieved chunks\n",
    "    \n",
    "    Args:\n",
    "        query: The user's question\n",
    "        chunks: List of text chunks to use as context\n",
    "        max_chunks: Maximum number of chunks to use\n",
    "    \n",
    "    Returns:\n",
    "        Generated answer (string) or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Limit chunks to avoid token overflow\n",
    "        chunks_to_use = chunks[:max_chunks]\n",
    "        context = \"\\n\\n\".join([f\"[Chunk {i+1}]\\n{chunk}\" for i, chunk in enumerate(chunks_to_use)])\n",
    "        \n",
    "        system_prompt = \"\"\"You are a helpful financial analyst assistant. \n",
    "Based on the provided document chunks, answer the user's question accurately and concisely.\n",
    "If the information is not in the provided chunks, say 'I don't have enough information to answer this question.'\n",
    "Always cite which chunks you used to answer the question.\"\"\"\n",
    "        \n",
    "        user_message = f\"\"\"Question: {query}\n",
    "\n",
    "Document Chunks:\n",
    "{context}\n",
    "\n",
    "Please provide a clear, concise answer based on the above information.\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Error generating answer: {str(e)[:60]}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Utility functions defined!\")\n",
    "print()\n",
    "print(\"Functions available:\")\n",
    "print(\"  - fetch_and_extract_pdf(url): Fetch and extract text from PDFs\")\n",
    "print(\"  - fetch_and_extract_section_from_pdf(url): Extract sections from PDFs using PyMuPDF\")\n",
    "print(\"  - add_chunk_to_collection(): Add chunks to a collection\")\n",
    "print(\"  - query_collection(): Query a collection\")\n",
    "print(\"  - generate_rag_answer(): Generate LLM answers from chunks using GPT-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a05dfb",
   "metadata": {},
   "source": [
    "## Semantic Chunking Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9554f396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebby/05-src/personal/gh-ebbypeter/ELVTR-APAC-AISA1-SelfStudy/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import re\n",
    "\n",
    "def extract_semantic_chunk_pdf_from_url(pdf_url, document_type, threshold_amount=None, timeout=10):\n",
    "    \"\"\"\n",
    "    Fetch a PDF from a URL and chunk it based on document type using semantic chunking.\n",
    "    \n",
    "    Args:\n",
    "        pdf_url: URL to the PDF file\n",
    "        document_type: Type of document - 'press_release', 'transcript', or 'presentation'\n",
    "        threshold_amount: Optional custom threshold for semantic splitting (uses defaults if None)\n",
    "        timeout: Request timeout in seconds\n",
    "    \n",
    "    Returns:\n",
    "        List of chunk dictionaries with 'content' and 'metadata', or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Download PDF\n",
    "        response = requests.get(pdf_url, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Extract text from PDF\n",
    "        pdf_file = BytesIO(response.content)\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        \n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "        \n",
    "        text = text.strip()\n",
    "        \n",
    "        if not text:\n",
    "            print(f\"   âš ï¸  No text extracted from PDF\")\n",
    "            return None\n",
    "        \n",
    "        # Chunk the text\n",
    "        chunks = _chunk_text_by_type(\n",
    "            text=text,\n",
    "            document_type=document_type,\n",
    "            threshold_amount=threshold_amount\n",
    "        )\n",
    "        \n",
    "        # Add PDF URL to metadata\n",
    "        for chunk in chunks:\n",
    "            chunk['metadata']['source_url'] = pdf_url\n",
    "        \n",
    "        return chunks if chunks else None\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"   âš ï¸  Error downloading PDF: {str(e)[:60]}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Error chunking PDF: {str(e)[:60]}\")\n",
    "        return None\n",
    "\n",
    "def _chunk_text_by_type(text, document_type, threshold_amount=None):\n",
    "    \"\"\"\n",
    "    Internal function to chunk text based on document type.\n",
    "    \n",
    "    Args:\n",
    "        text: Text content to chunk\n",
    "        document_type: Type of document\n",
    "        threshold_amount: Optional custom threshold\n",
    "        \n",
    "    Returns:\n",
    "        List of chunk dictionaries\n",
    "    \"\"\"\n",
    "    document_type = document_type.lower()\n",
    "    \n",
    "    # Validate document type\n",
    "    valid_types = ['press_release', 'followup_qa', 'earnings_call', 'presentation']\n",
    "    if document_type not in valid_types:\n",
    "        print(f\"   âš ï¸  Invalid document_type: '{document_type}'\")\n",
    "        return None\n",
    "    \n",
    "    # Set default thresholds if not provided\n",
    "    if threshold_amount is None:\n",
    "        threshold_defaults = {\n",
    "            'press_release': 90,\n",
    "            'followup_qa': 85,\n",
    "            'earnings_call': 85,\n",
    "            'presentation': 88\n",
    "        }\n",
    "        threshold_amount = threshold_defaults[document_type]\n",
    "    \n",
    "    # Handle presentation differently (no semantic chunking needed)\n",
    "    if document_type == 'presentation':\n",
    "        return _chunk_presentation(text)\n",
    "    \n",
    "    # Use semantic chunking for press_release and transcript\n",
    "    try:\n",
    "        # from langchain_text_splitters import SemanticChunker\n",
    "        # from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "        \n",
    "        # embeddings = HuggingFaceEmbeddings(\n",
    "        #     model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "        # )\n",
    "        \n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        \n",
    "        splitter = SemanticChunker(\n",
    "            embeddings,\n",
    "            breakpoint_threshold_type=\"percentile\",\n",
    "            breakpoint_threshold_amount=threshold_amount\n",
    "        )\n",
    "        \n",
    "        chunks = splitter.create_documents([text])\n",
    "        \n",
    "        # Format chunks based on document type\n",
    "        if document_type == 'followup_qa' or document_type == 'earnings_call':\n",
    "            return _format_transcript_chunks(chunks)\n",
    "        else:  # press_release\n",
    "            return _format_standard_chunks(chunks, document_type)\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(f\"   âš ï¸  Missing required library: {str(e)[:60]}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Error in semantic chunking: {str(e)[:60]}\")\n",
    "        return None\n",
    "\n",
    "def _chunk_presentation(text, min_slide_length=100):\n",
    "    \"\"\"Chunk presentation by splitting on slide indicators\"\"\"\n",
    "    try:\n",
    "        slide_pattern = r'\\n\\d+\\n'\n",
    "        slides = re.split(slide_pattern, text)\n",
    "        \n",
    "        chunks = []\n",
    "        for slide_num, slide_content in enumerate(slides, 1):\n",
    "            if len(slide_content.strip()) > min_slide_length:\n",
    "                chunks.append({\n",
    "                    'content': slide_content.strip(),\n",
    "                    'metadata': {\n",
    "                        'chunk_id': slide_num - 1,\n",
    "                        'doc_type': 'presentation',\n",
    "                        'slide_number': slide_num,\n",
    "                        'has_chart': 'revenue' in slide_content.lower() or '$' in slide_content,\n",
    "                        'word_count': len(slide_content.split()),\n",
    "                        'has_numbers': bool(re.search(r'\\$?\\d+[\\d,]*\\.?\\d*[BMK]?', slide_content))\n",
    "                    }\n",
    "                })\n",
    "        \n",
    "        return chunks if chunks else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Error chunking presentation: {str(e)[:60]}\")\n",
    "        return None\n",
    "\n",
    "def _format_standard_chunks(chunks, doc_type):\n",
    "    \"\"\"Format chunks for press releases and other standard documents\"\"\"\n",
    "    try:\n",
    "        formatted = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            formatted.append({\n",
    "                'content': chunk.page_content,\n",
    "                'metadata': {\n",
    "                    'chunk_id': i,\n",
    "                    'doc_type': doc_type,\n",
    "                    'word_count': len(chunk.page_content.split()),\n",
    "                    'char_count': len(chunk.page_content),\n",
    "                    'has_numbers': bool(re.search(r'\\$?\\d+[\\d,]*\\.?\\d*[BMK]?', chunk.page_content))\n",
    "                }\n",
    "            })\n",
    "        return formatted\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Error formatting chunks: {str(e)[:60]}\")\n",
    "        return None\n",
    "\n",
    "def _format_transcript_chunks(chunks):\n",
    "    \"\"\"Format chunks for transcripts with speaker detection\"\"\"\n",
    "    try:\n",
    "        formatted = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            content = chunk.page_content\n",
    "            \n",
    "            # Try to extract speaker name\n",
    "            speaker_match = re.search(r'^([\\w\\s]+):', content, re.MULTILINE)\n",
    "            speaker = speaker_match.group(1).strip() if speaker_match else \"Unknown\"\n",
    "            \n",
    "            # Detect if this is a question\n",
    "            has_question = bool(re.search(r'\\?', content))\n",
    "            \n",
    "            formatted.append({\n",
    "                'content': content,\n",
    "                'metadata': {\n",
    "                    'chunk_id': i,\n",
    "                    'doc_type': 'transcript',\n",
    "                    'speaker': speaker,\n",
    "                    'word_count': len(content.split()),\n",
    "                    'char_count': len(content),\n",
    "                    'has_numbers': bool(re.search(r'\\$?\\d+[\\d,]*\\.?\\d*[BMK]?', content)),\n",
    "                    'has_question': has_question\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        return formatted\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Error formatting transcript chunks: {str(e)[:60]}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89205808",
   "metadata": {},
   "source": [
    "## Initialize ChromaDB Collections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d864b",
   "metadata": {},
   "source": [
    "### Strategy 1 - By Page\n",
    "\n",
    "By Page chunking splits documents at natural page boundaries, treating each page as a single chunk. \n",
    "\n",
    "This approach preserves the complete context within each page, making it ideal for structured documents like financial reports where tables, charts, and related metrics are often grouped on the same page. \n",
    "\n",
    "The strategy is simple to implement, deterministic, and ensures that page-level formatting and layout relationships remain intact. \n",
    "However, it may include irrelevant content from the same page and can create unnecessarily large chunks if pages contain diverse topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7458b41",
   "metadata": {},
   "source": [
    "#### Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80837dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Strategy 1 - ByPage: BUILDING INDEX: PAGE-BASED CHUNKING (Each Page = 1 Chunk)\n",
      "======================================================================\n",
      "\n",
      "ğŸ”„ Processing Q1...\n",
      "  ğŸ“„ press_release... âœ… 8 pages\n",
      "  ğŸ“„ presentation... âœ… 17 pages\n",
      "  ğŸ“„ earnings_call... âœ… 18 pages\n",
      "  ğŸ“„ followup_qa... âœ… 10 pages\n",
      "\n",
      "ğŸ”„ Processing Q2...\n",
      "  ğŸ“„ press_release... âœ… 8 pages\n",
      "  ğŸ“„ presentation... âœ… 17 pages\n",
      "  ğŸ“„ earnings_call... âœ… 18 pages\n",
      "  ğŸ“„ followup_qa... âœ… 9 pages\n",
      "\n",
      "ğŸ”„ Processing Q3...\n",
      "  ğŸ“„ press_release... âœ… 8 pages\n",
      "  ğŸ“„ presentation... âœ… 17 pages\n",
      "  ğŸ“„ earnings_call... âœ… 18 pages\n",
      "  ğŸ“„ followup_qa... âœ… 9 pages\n",
      "\n",
      "ğŸ”„ Processing Q4...\n",
      "  ğŸ“„ press_release... âœ… 8 pages\n",
      "  ğŸ“„ presentation... âœ… 17 pages\n",
      "  ğŸ“„ earnings_call... âœ… 20 pages\n",
      "  ğŸ“„ followup_qa... âœ… 10 pages\n",
      "\n",
      "âœ… Strategy 1: Added 228 page-based chunks to collection!\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Strategy 1 - ByPage: BUILDING INDEX: PAGE-BASED CHUNKING (Each Page = 1 Chunk)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s1_bypage_collection = chroma_client.get_or_create_collection(\n",
    "    name=\"Strategy1_ByPage_Collection\",\n",
    "    metadata={\"description\": \"Chunks created by treating each PDF page as a separate chunk\"}\n",
    ")\n",
    "\n",
    "s1_chunk_count = 0\n",
    "for quarter in data_sources:\n",
    "    print(f\"\\nğŸ”„ Processing {quarter}...\")\n",
    "    for doc_type in data_sources[quarter]:\n",
    "        print(f\"  ğŸ“„ {doc_type}...\", end=\"\")\n",
    "        \n",
    "        # Fetch PDF data\n",
    "        pdf_url = data_sources[quarter][doc_type]\n",
    "        pages = fetch_and_extract_pdf(pdf_url, return_type=\"Pages\")\n",
    "        \n",
    "        if not pages:\n",
    "            print(f\"   âš ï¸  No text extracted from {pdf_url}\")\n",
    "            continue\n",
    "        \n",
    "        # Strategy 1: Each page is one chunk  \n",
    "        for i, page_text in enumerate(pages):\n",
    "            chunk_id = f\"{quarter}_{doc_type}_s1_page_{i+1}\"\n",
    "            add_chunk_to_collection(s1_bypage_collection, doc_type, quarter, page_text, chunk_id)\n",
    "            s1_chunk_count += 1\n",
    "            \n",
    "        print(f\" âœ… {i} pages\")\n",
    "        \n",
    "print(f\"\\nâœ… Strategy 1: Added {s1_chunk_count} page-based chunks to collection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea1bf7",
   "metadata": {},
   "source": [
    "#### Inspect Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c4151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Strategy 1 - ByPage: INSPECT INDEX : PAGE-BASED CHUNKING (Each Page = 1 Chunk)\n",
      "======================================================================\n",
      "\n",
      "âœ… Total documents in ByPage Index: 228\n",
      "Strategy 1 - ByPage - Statistics:\n",
      "   Average chunk size: 2175 characters\n",
      "   Minimum chunk size: 8 characters\n",
      "   Maximum chunk size: 5375 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Strategy 1 - ByPage: INSPECT INDEX : PAGE-BASED CHUNKING (Each Page = 1 Chunk)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get all documents in the collection\n",
    "s1_all_docs = query_collection(s1_bypage_collection)\n",
    "\n",
    "print(f\"\\nâœ… Total documents in ByPage Index: {len(s1_all_docs['documents'])}\")\n",
    "print(f\"Strategy 1 - ByPage - Statistics:\")\n",
    "s1_chunk_sizes = [m['chunk_length'] for m in s1_all_docs['metadatas']]\n",
    "print(f\"   Average chunk size: {sum(s1_chunk_sizes) / len(s1_chunk_sizes):.0f} characters\")\n",
    "print(f\"   Minimum chunk size: {min(s1_chunk_sizes)} characters\")\n",
    "print(f\"   Maximum chunk size: {max(s1_chunk_sizes)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c187a",
   "metadata": {},
   "source": [
    "### Strategy 2 - By Sentences (3)\n",
    "\n",
    "By Sentence chunking groups consecutive sentences into fixed-size chunks. In this case, every 3 sentences form one chunk. \n",
    "\n",
    "This method provides consistent, small-sized chunks that are easy to process and can capture local context around individual facts or statements. The approach works well for simple factual queries where answers are contained in a few sentences. \n",
    "\n",
    "However, it struggles with longer narratives or explanations that span many sentences, often fragmenting content across multiple chunks and making it difficult to retrieve complete context for complex questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c3932e",
   "metadata": {},
   "source": [
    "#### Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49951e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Strategy 2 - BySentences: BUILDING INDEX: SENTENCE BASED CHUNKING (3 x Sentences = 1 Chunk)\n",
      "======================================================================\n",
      "\n",
      "ğŸ”„ Processing Q1...\n",
      "  ğŸ“„ press_release... âœ… 108 sentences grouped into 36 chunks\n",
      "  ğŸ“„ presentation... âœ… 99 sentences grouped into 33 chunks\n",
      "  ğŸ“„ earnings_call... âœ… 460 sentences grouped into 154 chunks\n",
      "  ğŸ“„ followup_qa... âœ… 275 sentences grouped into 92 chunks\n",
      "\n",
      "ğŸ”„ Processing Q2...\n",
      "  ğŸ“„ press_release... âœ… 120 sentences grouped into 40 chunks\n",
      "  ğŸ“„ presentation... âœ… 99 sentences grouped into 33 chunks\n",
      "  ğŸ“„ earnings_call... âœ… 459 sentences grouped into 153 chunks\n",
      "  ğŸ“„ followup_qa... âœ… 234 sentences grouped into 78 chunks\n",
      "\n",
      "ğŸ”„ Processing Q3...\n",
      "  ğŸ“„ press_release... âœ… 144 sentences grouped into 48 chunks\n",
      "  ğŸ“„ presentation... âœ… 114 sentences grouped into 38 chunks\n",
      "  ğŸ“„ earnings_call... âœ… 443 sentences grouped into 148 chunks\n",
      "  ğŸ“„ followup_qa... âœ… 243 sentences grouped into 81 chunks\n",
      "\n",
      "ğŸ”„ Processing Q4...\n",
      "  ğŸ“„ press_release... âœ… 128 sentences grouped into 43 chunks\n",
      "  ğŸ“„ presentation... âœ… 115 sentences grouped into 39 chunks\n",
      "  ğŸ“„ earnings_call... âœ… 473 sentences grouped into 158 chunks\n",
      "  ğŸ“„ followup_qa... âœ… 261 sentences grouped into 87 chunks\n",
      "\n",
      "âœ… Strategy 2: Added 1261 sentence-based chunks to collection!\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Strategy 2 - BySentences: BUILDING INDEX: SENTENCE BASED CHUNKING (3 x Sentences = 1 Chunk)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s2_bysentences_collection = chroma_client.get_or_create_collection(\n",
    "    name=\"Strategy2_BySentences_Collection\",\n",
    "    metadata={\"description\": \"Chunks created by grouping every 3 sentences together\"}\n",
    ")\n",
    "\n",
    "s2_chunk_count = 0\n",
    "for quarter in data_sources:\n",
    "    print(f\"\\nğŸ”„ Processing {quarter}...\")\n",
    "    for doc_type in data_sources[quarter]:\n",
    "        print(f\"  ğŸ“„ {doc_type}...\", end=\"\")\n",
    "        \n",
    "        # Fetch PDF data\n",
    "        pdf_url = data_sources[quarter][doc_type]\n",
    "        text = fetch_and_extract_pdf(pdf_url, return_type=\"Text\")\n",
    "        \n",
    "        if not text:\n",
    "            print(f\"   âš ï¸  No text extracted from {pdf_url}\")\n",
    "            continue\n",
    "        \n",
    "        # Strategy 2: Group every 3 sentences into one chunk\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        for i in range(0, len(sentences), 3):\n",
    "            chunk_sentences = sentences[i:i+3]\n",
    "            chunk_text = '. '.join(chunk_sentences) + ('.' if chunk_sentences else '')\n",
    "            chunk_id = f\"{quarter}_{doc_type}_s2_sentences_{i//3 + 1}\"\n",
    "            add_chunk_to_collection(s2_bysentences_collection, doc_type, quarter, chunk_text, chunk_id)\n",
    "            s2_chunk_count += 1\n",
    "            \n",
    "        print(f\" âœ… {len(sentences)} sentences grouped into {len(sentences) // 3 + (1 if len(sentences) % 3 > 0 else 0)} chunks\")\n",
    "        \n",
    "print(f\"\\nâœ… Strategy 2: Added {s2_chunk_count} sentence-based chunks to collection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0107bbb9",
   "metadata": {},
   "source": [
    "#### Inspect Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98aaa881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Strategy 2 - BySentence: INSPECT INDEX : SENTENCE BASED CHUNKING (3 x Sentences = 1 Chunk)\n",
      "======================================================================\n",
      "\n",
      "âœ… Total documents in BySentence Index: 1261\n",
      "Strategy 2 - BySentence - Statistics:\n",
      "   Average chunk size: 389 characters\n",
      "   Minimum chunk size: 4 characters\n",
      "   Maximum chunk size: 4926 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Strategy 2 - BySentence: INSPECT INDEX : SENTENCE BASED CHUNKING (3 x Sentences = 1 Chunk)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get all documents in the collection\n",
    "s2_all_docs = query_collection(s2_bysentences_collection)\n",
    "\n",
    "print(f\"\\nâœ… Total documents in BySentence Index: {len(s2_all_docs['documents'])}\")\n",
    "print(f\"Strategy 2 - BySentence - Statistics:\")\n",
    "s2_chunk_sizes = [m['chunk_length'] for m in s2_all_docs['metadatas']]\n",
    "print(f\"   Average chunk size: {sum(s2_chunk_sizes) / len(s2_chunk_sizes):.0f} characters\")\n",
    "print(f\"   Minimum chunk size: {min(s2_chunk_sizes)} characters\")\n",
    "print(f\"   Maximum chunk size: {max(s2_chunk_sizes)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924579d6",
   "metadata": {},
   "source": [
    "### Strategy 3 - By Sections\n",
    "\n",
    "By Section chunking uses document formatting cues, specifically bold text, larger font sizes, and uppercase textâ€”to detect section headings and split content at these boundaries. \n",
    "\n",
    "This approach creates semantically meaningful chunks by preserving complete sections like \"CFO Outlook,\" \"Q&A Session,\" or \"Revenue Analysis\" as unified chunks. It's highly efficient when documents have clear hierarchical structure with consistent formatting. \n",
    "\n",
    "However, it can fail when important content (like financial tables) lacks section headers or when font detection is unreliable, leading to missed or improperly split content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddf44c",
   "metadata": {},
   "source": [
    "#### Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192b7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Strategy 3 - BySections: BUILDING INDEX: SECTION BASED CHUNKING (1 Section = 1 Chunk)\n",
      "======================================================================\n",
      "\n",
      "ğŸ”„ Processing Q1...\n",
      "  ğŸ“„ press_release... âœ… Extracted 44 sections\n",
      "  ğŸ“„ presentation...   âš ï¸  No sections extracted from https://s21.q4cdn.com/399680738/files/doc_financials/2025/q1/Earnings-Presentation-Q1-2025-FINAL.pdf\n",
      "   Falling back to Sentence-based chunking...\n",
      "  ğŸ“„ earnings_call...   âš ï¸  No sections extracted from https://s21.q4cdn.com/399680738/files/doc_financials/2025/q1/Transcripts/META-Q1-2025-Earnings-Call-Transcript-1.pdf\n",
      "   Falling back to Sentence-based chunking...\n",
      "  ğŸ“„ followup_qa... âœ… Extracted 11 sections\n",
      "\n",
      "ğŸ”„ Processing Q2...\n",
      "  ğŸ“„ press_release... âœ… Extracted 43 sections\n",
      "  ğŸ“„ presentation...   âš ï¸  No sections extracted from https://s21.q4cdn.com/399680738/files/doc_downloads/Earnings-Presentation-Q2-2025-FINAL.pdf\n",
      "   Falling back to Sentence-based chunking...\n",
      "  ğŸ“„ earnings_call...   âš ï¸  No sections extracted from https://s21.q4cdn.com/399680738/files/doc_financials/2025/q2/META-Q2-2025-Earnings-Call-Transcript.pdf\n",
      "   Falling back to Sentence-based chunking...\n",
      "  ğŸ“„ followup_qa...   âš ï¸  No sections extracted from https://s21.q4cdn.com/399680738/files/doc_financials/2025/q2/META-Q2-2025-Follow-Up-Call-Transcript.pdf\n",
      "   Falling back to Sentence-based chunking...\n",
      "\n",
      "ğŸ”„ Processing Q3...\n",
      "  ğŸ“„ press_release... âœ… Extracted 48 sections\n",
      "  ğŸ“„ presentation...   âš ï¸  No sections extracted from https://s21.q4cdn.com/399680738/files/doc_financials/2025/q3/Earnings-Presentation-Q3-2025-Final.pdf\n",
      "   Falling back to Sentence-based chunking...\n",
      "  ğŸ“„ earnings_call...   âš ï¸  No sections extracted from https://s21.q4cdn.com/399680738/files/doc_financials/2025/q3/META-Q3-2025-Earnings-Call-Transcript.pdf\n",
      "   Falling back to Sentence-based chunking...\n",
      "  ğŸ“„ followup_qa...   âš ï¸  No sections extracted from https://s21.q4cdn.com/399680738/files/doc_financials/2025/q3/META-Q3-2025-Follow-Up-Call-Transcript.pdf\n",
      "   Falling back to Sentence-based chunking...\n",
      "\n",
      "ğŸ”„ Processing Q4...\n",
      "  ğŸ“„ press_release... âœ… Extracted 49 sections\n",
      "  ğŸ“„ presentation...   âš ï¸  No sections extracted from https://s21.q4cdn.com/399680738/files/doc_financials/2025/q4/Earnings-Presentation-Q4-2025-FINAL.pdf\n",
      "   Falling back to Sentence-based chunking...\n",
      "  ğŸ“„ earnings_call... âœ… Extracted 1 sections\n",
      "  ğŸ“„ followup_qa...   âš ï¸  No sections extracted from https://s21.q4cdn.com/399680738/files/doc_financials/2025/q4/META-Q4-2025-Follow-Up-Call-Transcript.pdf\n",
      "   Falling back to Sentence-based chunking...\n",
      "\n",
      "âœ… Strategy 3: Added 356 section-based chunks to collection!\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Strategy 3 - BySections: BUILDING INDEX: SECTION BASED CHUNKING (1 Section = 1 Chunk)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s3_bysections_collection = chroma_client.get_or_create_collection(\n",
    "    name=\"Strategy3_BySections_Collection\",\n",
    "    metadata={\"description\": \"Chunks created by treating each section as a separate chunk\"}\n",
    ")\n",
    "\n",
    "s3_chunk_count = 0\n",
    "for quarter in data_sources:\n",
    "    print(f\"\\nğŸ”„ Processing {quarter}...\")\n",
    "    for doc_type in data_sources[quarter]:\n",
    "        print(f\"  ğŸ“„ {doc_type}...\", end=\"\")\n",
    "        \n",
    "        # Fetch PDF data\n",
    "        pdf_url = data_sources[quarter][doc_type]\n",
    "\n",
    "        sections = fetch_and_extract_section_from_pdf(pdf_url)\n",
    "        if not sections or len(sections) == 0:\n",
    "            print(f\"   âš ï¸  No sections extracted from {pdf_url}\")\n",
    "            print(f\"   Falling back to Sentence-based chunking...\")\n",
    "            pages = fetch_and_extract_pdf(pdf_url, return_type=\"Pages\")\n",
    "            if not pages:\n",
    "                print(f\"   âš ï¸  No text extracted from {pdf_url}\")\n",
    "                continue\n",
    "            for i, page_text in enumerate(pages):\n",
    "                chunk_id = f\"{quarter}_{doc_type}_s1_page_{i+1}\"\n",
    "                add_chunk_to_collection(s3_bysections_collection, doc_type, quarter, page_text, chunk_id)\n",
    "                s3_chunk_count += 1\n",
    "            # Add pages to collection as fallback\n",
    "            continue\n",
    "        \n",
    "        print(f\" âœ… Extracted {len(sections) if sections else 0} sections\")\n",
    "        for section in sections:\n",
    "                chunk_id = f\"{quarter}_{doc_type}_s3_section_{s3_chunk_count + 1}\"\n",
    "                add_chunk_to_collection(s3_bysections_collection, doc_type, quarter, section['content'], chunk_id)\n",
    "                s3_chunk_count += 1\n",
    "            \n",
    "print(f\"\\nâœ… Strategy 3: Added {s3_chunk_count} section-based chunks to collection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77430f",
   "metadata": {},
   "source": [
    "#### Inspect Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84a9b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Strategy 3 - ByParagraphs: INSPECT INDEX : PARAGRAPH BASED CHUNKING (1 Paragraph = 1 Chunk)\n",
      "======================================================================\n",
      "\n",
      "âœ… Total documents in BySection Index: 356\n",
      "Strategy 3 - BySections - Statistics:\n",
      "   Average chunk size: 1299 characters\n",
      "   Minimum chunk size: 6 characters\n",
      "   Maximum chunk size: 38090 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Strategy 3 - ByParagraphs: INSPECT INDEX : PARAGRAPH BASED CHUNKING (1 Paragraph = 1 Chunk)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get all documents in the collection\n",
    "s3_all_docs = query_collection(s3_bysections_collection)\n",
    "print(f\"\\nâœ… Total documents in BySection Index: {len(s3_all_docs['documents'])}\")\n",
    "print(f\"Strategy 3 - BySections - Statistics:\")\n",
    "s3_chunk_sizes = [m['chunk_length'] for m in s3_all_docs['metadatas']]\n",
    "print(f\"   Average chunk size: {sum(s3_chunk_sizes) / len(s3_chunk_sizes):.0f} characters\")\n",
    "print(f\"   Minimum chunk size: {min(s3_chunk_sizes)} characters\")\n",
    "print(f\"   Maximum chunk size: {max(s3_chunk_sizes)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2024b3",
   "metadata": {},
   "source": [
    "### Strategy 4 - Fixed Token Length\n",
    "\n",
    "By Fixed Token Length chunking divides text into uniform chunks of a predetermined token count (e.g., 512 tokens each), often with overlapping windows to maintain some continuity between chunks. \n",
    "\n",
    "This method guarantees predictable chunk sizes, which is useful for managing token limits in language models and ensuring consistent computational costs. \n",
    "\n",
    "While simple and deterministic, this approach completely ignores semantic boundariesâ€”it can split sentences mid-way, fragment tables, or separate questions from answers. \n",
    "This arbitrary splitting often results in poor retrieval quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d93c56",
   "metadata": {},
   "source": [
    "#### Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d72f4f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Strategy 4 - Fixed Token: BUILDING INDEX: FIXED TOKEN CHUNKING (1 Chunk = Fixed Token Length)\n",
      "======================================================================\n",
      "\n",
      "ğŸ”„ Processing Q1...\n",
      "  ğŸ“„ press_release... âœ… 2519 words split into 5 chunks\n",
      "  ğŸ“„ presentation... âœ… 2676 words split into 6 chunks\n",
      "  ğŸ“„ earnings_call... âœ… 9344 words split into 19 chunks\n",
      "  ğŸ“„ followup_qa... âœ… 5372 words split into 11 chunks\n",
      "\n",
      "ğŸ”„ Processing Q2...\n",
      "  ğŸ“„ press_release... âœ… 2974 words split into 6 chunks\n",
      "  ğŸ“„ presentation... âœ… 2668 words split into 6 chunks\n",
      "  ğŸ“„ earnings_call... âœ… 9622 words split into 19 chunks\n",
      "  ğŸ“„ followup_qa... âœ… 4607 words split into 9 chunks\n",
      "\n",
      "ğŸ”„ Processing Q3...\n",
      "  ğŸ“„ press_release... âœ… 3277 words split into 7 chunks\n",
      "  ğŸ“„ presentation... âœ… 2861 words split into 6 chunks\n",
      "  ğŸ“„ earnings_call... âœ… 9682 words split into 19 chunks\n",
      "  ğŸ“„ followup_qa... âœ… 4645 words split into 10 chunks\n",
      "\n",
      "ğŸ”„ Processing Q4...\n",
      "  ğŸ“„ press_release... âœ… 3019 words split into 6 chunks\n",
      "  ğŸ“„ presentation... âœ… 2925 words split into 6 chunks\n",
      "  ğŸ“„ earnings_call... âœ… 9995 words split into 20 chunks\n",
      "  ğŸ“„ followup_qa... âœ… 5080 words split into 10 chunks\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Strategy 4 - Fixed Token: BUILDING INDEX: FIXED TOKEN CHUNKING (1 Chunk = Fixed Token Length)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s4_fixedtoken_collection = chroma_client.get_or_create_collection(\n",
    "    name=\"Strategy4_FixedToken_Collection\",\n",
    "    metadata={\"description\": \"Chunks created by splitting text into fixed token lengths (e.g., 1000 tokens per chunk)\"}\n",
    ")\n",
    "\n",
    "s4_chunk_count = 0\n",
    "for quarter in data_sources:\n",
    "    print(f\"\\nğŸ”„ Processing {quarter}...\")\n",
    "    for doc_type in data_sources[quarter]:\n",
    "        print(f\"  ğŸ“„ {doc_type}...\", end=\"\")\n",
    "        \n",
    "        # Fetch PDF data\n",
    "        pdf_url = data_sources[quarter][doc_type]\n",
    "        text = fetch_and_extract_pdf(pdf_url, return_type=\"Text\")\n",
    "        \n",
    "        if not text:\n",
    "            print(f\"   âš ï¸  No text extracted from {pdf_url}\")\n",
    "            continue\n",
    "        \n",
    "        # Strategy 4: Split text into fixed token length chunks (e.g., 1000 tokens)\n",
    "        # For simplicity, we'll approximate tokens by splitting on whitespace and punctuation\n",
    "        chunk_size = 512  # Approximate number of tokens per chunk\n",
    "        overlap = 100    # Number of words to overlap between chunks to maintain context\n",
    "        \n",
    "        start = 0\n",
    "        while start < len(text):\n",
    "             end = start + chunk_size\n",
    "             chunk_text = text[start:end]\n",
    "             \n",
    "             chunk_id = f\"{quarter}_{doc_type}_s4_fixedtoken_{s4_chunk_count + 1}\"\n",
    "             add_chunk_to_collection(s4_fixedtoken_collection, doc_type, quarter, chunk_text, chunk_id)\n",
    "             s4_chunk_count += 1\n",
    "             start += (chunk_size - overlap)  # Move start forward with overlap\n",
    "            \n",
    "        print(f\" âœ… {len(text.split())} words split into {len(text.split()) // chunk_size + (1 if len(text.split()) % chunk_size > 0 else 0)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b652f",
   "metadata": {},
   "source": [
    "#### Inspect Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6a53108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Strategy 4 - Fixed Token: INSPECT INDEX: FIXED TOKEN CHUNKING (1 Chunk = Fixed Token Length)\n",
      "======================================================================\n",
      "\n",
      "âœ… Total documents in Fixed Token Index: 1212\n",
      "Strategy 4 - Fixed Token - Statistics:\n",
      "   Average chunk size: 508 characters\n",
      "   Minimum chunk size: 14 characters\n",
      "   Maximum chunk size: 512 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Strategy 4 - Fixed Token: INSPECT INDEX: FIXED TOKEN CHUNKING (1 Chunk = Fixed Token Length)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get all documents in the collection\n",
    "s4_all_docs = query_collection(s4_fixedtoken_collection)\n",
    "print(f\"\\nâœ… Total documents in Fixed Token Index: {len(s4_all_docs['documents'])}\")\n",
    "print(f\"Strategy 4 - Fixed Token - Statistics:\")\n",
    "s4_chunk_sizes = [m['chunk_length'] for m in s4_all_docs['metadatas']]\n",
    "print(f\"   Average chunk size: {sum(s4_chunk_sizes) / len(s4_chunk_sizes):.0f} characters\")\n",
    "print(f\"   Minimum chunk size: {min(s4_chunk_sizes)} characters\")\n",
    "print(f\"   Maximum chunk size: {max(s4_chunk_sizes)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f0ace",
   "metadata": {},
   "source": [
    "### Strategy 5 - Semantic Chunking\n",
    "\n",
    "By Semantic Chunking uses embeddings to analyze the semantic similarity between consecutive sentences and identifies natural topic boundaries where similarity drops significantly. \n",
    "\n",
    "When the model detects a shift in topic or context, it creates a new chunk, ensuring that semantically related content stays together. This intelligent approach preserves narrative coherence, keeps question-answer pairs intact, and maintains complete explanations without arbitrary splits. It adapts to the content's natural structure rather than imposing fixed rules, making it the most robust strategy across diverse query typesâ€”from simple facts to complex narrativesâ€”though it requires computational resources for embedding generation.\n",
    "\n",
    "However, this approach is significantly complicated to implement compared to other strategies and will need to use embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f19084",
   "metadata": {},
   "source": [
    "#### Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89005825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Strategy 5 - Semantic Chunking: BUILDING INDEX\n",
      "======================================================================\n",
      "\n",
      "ğŸ”„ Processing Q1...\n",
      "  ğŸ“„ press_release... âœ… Created 8 semantic chunks\n",
      "  ğŸ“„ presentation... âœ… Created 4 semantic chunks\n",
      "  ğŸ“„ earnings_call... âœ… Created 70 semantic chunks\n",
      "  ğŸ“„ followup_qa... âœ… Created 45 semantic chunks\n",
      "\n",
      "ğŸ”„ Processing Q2...\n",
      "  ğŸ“„ press_release... âœ… Created 9 semantic chunks\n",
      "  ğŸ“„ presentation... âœ… Created 4 semantic chunks\n",
      "  ğŸ“„ earnings_call... âœ… Created 69 semantic chunks\n",
      "  ğŸ“„ followup_qa... âœ… Created 39 semantic chunks\n",
      "\n",
      "ğŸ”„ Processing Q3...\n",
      "  ğŸ“„ press_release... âœ… Created 10 semantic chunks\n",
      "  ğŸ“„ presentation... âœ… Created 2 semantic chunks\n",
      "  ğŸ“„ earnings_call... âœ… Created 68 semantic chunks\n",
      "  ğŸ“„ followup_qa... âœ… Created 40 semantic chunks\n",
      "\n",
      "ğŸ”„ Processing Q4...\n",
      "  ğŸ“„ press_release... âœ… Created 8 semantic chunks\n",
      "  ğŸ“„ presentation... âœ… Created 2 semantic chunks\n",
      "  ğŸ“„ earnings_call... âœ… Created 73 semantic chunks\n",
      "  ğŸ“„ followup_qa... âœ… Created 43 semantic chunks\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Strategy 5 - Semantic Chunking: BUILDING INDEX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s5_semantic_collection = chroma_client.get_or_create_collection(\n",
    "    name=\"Strategy5_SemanticChunking_Collection\",\n",
    "    metadata={\"description\": \"Chunks created using semantic chunking based on content and meaning\"}\n",
    ")\n",
    "\n",
    "s5_chunk_count = 0\n",
    "for quarter in data_sources:\n",
    "    print(f\"\\nğŸ”„ Processing {quarter}...\")\n",
    "    for doc_type in data_sources[quarter]:\n",
    "        print(f\"  ğŸ“„ {doc_type}...\", end=\"\")\n",
    "        \n",
    "        # Fetch PDF data and create semantic chunks\n",
    "        pdf_url = data_sources[quarter][doc_type]\n",
    "        chunks = extract_semantic_chunk_pdf_from_url(pdf_url, document_type=doc_type)\n",
    "        \n",
    "        if not chunks:\n",
    "            print(f\"   âš ï¸  No chunks created from {pdf_url}\")\n",
    "            continue\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            chunk_id = f\"{quarter}_{doc_type}_s5_semantic_{s5_chunk_count + 1}\"\n",
    "            add_chunk_to_collection(s5_semantic_collection, doc_type, quarter, chunk['content'], chunk_id)\n",
    "            s5_chunk_count += 1\n",
    "            \n",
    "        print(f\" âœ… Created {len(chunks)} semantic chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54996a",
   "metadata": {},
   "source": [
    "#### Inspect Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "005c124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Strategy 5 - Semantic Chunking: INSPECT INDEX\n",
      "======================================================================\n",
      "\n",
      "âœ… Total documents in Semantic Chunking Index: 494\n",
      "Strategy 5 - Semantic Chunking - Statistics:\n",
      "   Average chunk size: 992 characters\n",
      "   Minimum chunk size: 4 characters\n",
      "   Maximum chunk size: 16021 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Strategy 5 - Semantic Chunking: INSPECT INDEX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get all documents in the collection\n",
    "s5_all_docs = query_collection(s5_semantic_collection)\n",
    "print(f\"\\nâœ… Total documents in Semantic Chunking Index: {len(s5_all_docs['documents'])}\")\n",
    "print(f\"Strategy 5 - Semantic Chunking - Statistics:\")\n",
    "s5_chunk_sizes = [m['chunk_length'] for m in s5_all_docs['metadatas']]\n",
    "print(f\"   Average chunk size: {sum(s5_chunk_sizes) / len(s5_chunk_sizes):.0f} characters\")\n",
    "print(f\"   Minimum chunk size: {min(s5_chunk_sizes)} characters\")\n",
    "print(f\"   Maximum chunk size: {max(s5_chunk_sizes)} characters\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe88af",
   "metadata": {},
   "source": [
    "### Index Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25dea87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š INDEX COMPARISON:\n",
      "----------------------------------------------------------------------\n",
      "Strategy 1 - ByPage     : Documents =   228 | Avg Size =   2175 chars\n",
      "Strategy 2 - BySentences: Documents =  1261 | Avg Size =    389 chars\n",
      "Strategy 3 - BySections : Documents =   356 | Avg Size =   1299 chars\n",
      "Strategy 4 - FixedToken : Documents =  1212 | Avg Size =    508 chars\n",
      "Strategy 5 - Semantic   : Documents =   494 | Avg Size =    992 chars\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nğŸ“Š INDEX COMPARISON:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(f\"Strategy 1 - ByPage     : Documents = {len(s1_all_docs['documents']):5d} | Avg Size = {sum([m['chunk_length'] for m in s1_all_docs['metadatas']]) / len(s1_all_docs['metadatas']):6.0f} chars\")\n",
    "print(f\"Strategy 2 - BySentences: Documents = {len(s2_all_docs['documents']):5d} | Avg Size = {sum([m['chunk_length'] for m in s2_all_docs['metadatas']]) / len(s2_all_docs['metadatas']):6.0f} chars\")\n",
    "print(f\"Strategy 3 - BySections : Documents = {len(s3_all_docs['documents']):5d} | Avg Size = {sum([m['chunk_length'] for m in s3_all_docs['metadatas']]) / len(s3_all_docs['metadatas']):6.0f} chars\")\n",
    "print(f\"Strategy 4 - FixedToken : Documents = {len(s4_all_docs['documents']):5d} | Avg Size = {sum([m['chunk_length'] for m in s4_all_docs['metadatas']]) / len(s4_all_docs['metadatas']):6.0f} chars\")\n",
    "print(f\"Strategy 5 - Semantic   : Documents = {len(s5_all_docs['documents']):5d} | Avg Size = {sum([m['chunk_length'] for m in s5_all_docs['metadatas']]) / len(s5_all_docs['metadatas']):6.0f} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37fcab",
   "metadata": {},
   "source": [
    "## Define RAG Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7200bb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ¯ RAG PROMPTS TO BE TESTED\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Œ Prompt 1: Simple Fact Question\n",
      "   Question: What was Meta's total revenue in Q2 2025?\n",
      "   Keywords: revenue, Q2, total\n",
      "   Relevant doc types: press_release\n",
      "\n",
      "ğŸ“Œ Prompt 2: Long Explanation Question\n",
      "   Question: Explain Mark Zuckerberg's five major AI opportunities and how they relate to Meta's business strategy.\n",
      "   Keywords: AI opportunities, Zuckerberg, strategy\n",
      "   Relevant doc types: earnings_call\n",
      "\n",
      "ğŸ“Œ Prompt 3: Comparison Question\n",
      "   Question: Compare Meta's operating margin across Q1, Q2, Q3, and Q4 2025. Which quarter had the highest margin and why?\n",
      "   Keywords: operating margin, Q1, Q2, Q3, Q4\n",
      "   Relevant doc types: press_release, presentation\n",
      "\n",
      "ğŸ“Œ Prompt 4: Specific Speaker Question\n",
      "   Question: What did Susan Li say about European regulatory headwinds and DMA compliance in the earnings calls?\n",
      "   Keywords: Susan Li, DMA, Europe, regulatory\n",
      "   Relevant doc types: earnings_call, followup_qa\n",
      "\n",
      "ğŸ“Œ Prompt 5: Technical Detail Question\n",
      "   Question: How does Meta's GEM (Generative Ads Recommendation model) work and what improvements did it deliver?\n",
      "   Keywords: GEM, ads recommendation, model\n",
      "   Relevant doc types: earnings_call, followup_qa\n",
      "\n",
      "ğŸ“Œ Prompt 6: Future Guidance Question\n",
      "   Question: What is Meta's guidance for Q4 2025 revenue and capital expenditures?\n",
      "   Keywords: guidance, Q4, outlook, capex\n",
      "   Relevant doc types: press_release, earnings_call\n"
     ]
    }
   ],
   "source": [
    "# Define 3 clear RAG prompts\n",
    "rag_prompts = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"title\": \"Simple Fact Question\",\n",
    "        \"query\": \"What was Meta's total revenue in Q2 2025?\",\n",
    "        \"search_keywords\": [\"revenue\", \"Q2\", \"total\"],\n",
    "        \"doc_types\": [\"press_release\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"title\": \"Long Explanation Question\",\n",
    "        \"query\": \"Explain Mark Zuckerberg's five major AI opportunities and how they relate to Meta's business strategy.\",\n",
    "        \"search_keywords\": [\"AI opportunities\", \"Zuckerberg\", \"strategy\"],\n",
    "        \"doc_types\": [\"earnings_call\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"title\": \"Comparison Question\",\n",
    "        \"query\": \"Compare Meta's operating margin across Q1, Q2, Q3, and Q4 2025. Which quarter had the highest margin and why?\",\n",
    "        \"search_keywords\": [\"operating margin\", \"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n",
    "        \"doc_types\": [\"press_release\", \"presentation\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"title\": \"Specific Speaker Question\",\n",
    "        \"query\": \"What did Susan Li say about European regulatory headwinds and DMA compliance in the earnings calls?\",\n",
    "        \"search_keywords\": [\"Susan Li\", \"DMA\", \"Europe\", \"regulatory\"],\n",
    "        \"doc_types\": [\"earnings_call\", \"followup_qa\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"title\": \"Technical Detail Question\",\n",
    "        \"query\": \"How does Meta's GEM (Generative Ads Recommendation model) work and what improvements did it deliver?\",\n",
    "        \"search_keywords\": [\"GEM\", \"ads recommendation\", \"model\"],\n",
    "        \"doc_types\": [\"earnings_call\", \"followup_qa\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"title\": \"Future Guidance Question\",\n",
    "        \"query\": \"What is Meta's guidance for Q4 2025 revenue and capital expenditures?\",\n",
    "        \"search_keywords\": [\"guidance\", \"Q4\", \"outlook\", \"capex\"],\n",
    "        \"doc_types\": [\"press_release\", \"earnings_call\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ RAG PROMPTS TO BE TESTED\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for prompt in rag_prompts:\n",
    "    print(f\"\\nğŸ“Œ Prompt {prompt['id']}: {prompt['title']}\")\n",
    "    print(f\"   Question: {prompt['query']}\")\n",
    "    print(f\"   Keywords: {', '.join(prompt['search_keywords'])}\")\n",
    "    print(f\"   Relevant doc types: {', '.join(prompt['doc_types'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd5a4ce",
   "metadata": {},
   "source": [
    "##  Testing Prompts\n",
    "\n",
    "Run all RAG Prompts against the various indexing strategies and display results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca596bc8",
   "metadata": {},
   "source": [
    "### Strategy 1 - By Page\n",
    "Page-level segmentation maintaining document structure and pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bfc1e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ EXECUTING RAG PROMPTS ON STRATEGY 1 - BY PAGE INDEX\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Executing Prompt 1 on Strategy 1 - ByPage Index\n",
      "     Title: Simple Fact Question\n",
      "     Question: What was Meta's total revenue in Q2 2025?\n",
      "\n",
      "   Retrieved 32 relevant chunks from ByPage Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's total revenue in Q2 2025 was $47.516 billion. [Chunk 9]\n",
      "\n",
      "   Top 3 Retrieved Chunks of 32:\n",
      "   => Chunk ID: Q1_press_release_s1_page_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 2418 characters\n",
      "      Data: Meta Reports First Quarter 2025  Results\n",
      "MENLO PARK, Calif. â€“ April 30, 2025  â€“ Meta Platforms, Inc.\n",
      "\n",
      "   => Chunk ID: Q1_press_release_s1_page_2\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 1768 characters\n",
      "      Data: CFO Outlook Commentary\n",
      "We expect second quarter 2025 total revenue to be in the range of $ 42.5-45.5\n",
      "\n",
      "   => Chunk ID: Q1_press_release_s1_page_3\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 5346 characters\n",
      "      Data: Forward-Looking Statements\n",
      "This press release contains forward-looking statements regarding our futu\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 2 on Strategy 1 - ByPage Index\n",
      "     Title: Long Explanation Question\n",
      "     Question: Explain Mark Zuckerberg's five major AI opportunities and how they relate to Meta's business strategy.\n",
      "\n",
      "   Retrieved 30 relevant chunks from ByPage Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Mark Zuckerberg has identified five major AI opportunities that are integral to Meta's business strategy: improved advertising, more engaging experiences, business messaging, Meta AI, and AI devices. Each of these areas represents a long-term investment that builds on Meta's advancements in general intelligence and AI infrastructure.\n",
      "\n",
      "1. **Improved Advertising**: Meta aims to leverage AI to transform advertising into an AI-driven agent that delivers measurable business results at scale. AI enhances targeting, audience finding, and even ad creative generation, potentially increasing the share of global GDP attributed to advertising (Chunk 1).\n",
      "\n",
      "2. **More Engaging Experiences**: Meta is integrating AI into its Family of Apps and is also developing a standalone Meta AI app to enhance user experiences. This dual approach aims to provide faster access and a richer feature set, particularly valuable in markets like the U.S. where Meta aims to establish leadership in personal AI (Chunk 3).\n",
      "\n",
      "3. **Business Messaging**: AI in business messaging involves creating AI agents that can recall user history and preferences, streamlining interactions and saving businesses time. This approach enhances efficiency and decision-making for businesses using Meta's platforms (Chunk 6).\n",
      "\n",
      "4. **Meta AI**: Meta AI focuses on personalizing user experiences and integrating AI across its platforms. The AI aims to be a leader in personal AI by offering multimodal capabilities and understanding user preferences over time (Chunks 6, 12).\n",
      "\n",
      "5. **AI Devices**: The development of AI-powered devices, such as smart glasses, is a crucial part of Meta's strategy. These devices are seen as the ideal form factor for AI, offering functionalities like visual and auditory interaction with AI systems, which could potentially replace traditional smartphones and provide cognitive advantages (Chunk 15).\n",
      "\n",
      "These AI opportunities are aligned with Meta's broader business strategy by enhancing its core offerings, driving user engagement, and opening new revenue streams through advanced AI capabilities.\n",
      "\n",
      "   Top 3 Retrieved Chunks of 30:\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_1\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 3120 characters\n",
      "      Data: 1 \n",
      " Meta Platforms , Inc. ( META ) \n",
      "First Quarter 202 5 Results Conference Call  \n",
      "April 30th, 202 5 \n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_2\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 2912 characters\n",
      "      Data: 9 \n",
      " ads model is not compliant with the DMA. Based on feedback from the European Commission in \n",
      "conn\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_3\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 2584 characters\n",
      "      Data: 11 \n",
      "  \n",
      " Most of that, WhatsApp engagement is in one -on-one threads, followed by \n",
      "Facebook, which is\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 3 on Strategy 1 - ByPage Index\n",
      "     Title: Comparison Question\n",
      "     Question: Compare Meta's operating margin across Q1, Q2, Q3, and Q4 2025. Which quarter had the highest margin and why?\n",
      "\n",
      "   Retrieved 64 relevant chunks from ByPage Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Based on the provided document chunks, Meta's operating margins for each quarter of 2025 are as follows:\n",
      "\n",
      "- **Q1 2025:** 41% [Chunk 1]\n",
      "- **Q2 2025:** 43% [Chunk 2]\n",
      "- **Q3 2025:** 40% [Chunk 3]\n",
      "- **Q4 2025:** 41% [Chunk 4]\n",
      "\n",
      "The second quarter of 2025 had the highest operating margin at 43%. This increase in margin can be attributed to a combination of higher revenue growth (22% year-over-year) and a smaller percentage increase in costs and expenses (12% year-over-year) compared to other quarters, allowing for a greater proportion of revenue to translate into operating income.\n",
      "\n",
      "   Top 3 Retrieved Chunks of 64:\n",
      "   => Chunk ID: Q1_presentation_s1_page_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 2418 characters\n",
      "      Data: Meta Reports First Quarter 2025  Results\n",
      "MENLO PARK, Calif. â€“ April 30, 2025  â€“ Meta Platforms, Inc.\n",
      "\n",
      "   => Chunk ID: Q1_presentation_s1_page_2\n",
      "      Type: press_release | Quarter: Q2 | Chunk Length: 2314 characters\n",
      "      Data: Meta Reports Second  Quarter 2025  Results\n",
      "MENLO PARK, Calif. â€“ July 30, 2025  â€“ Meta Platforms, Inc\n",
      "\n",
      "   => Chunk ID: Q1_presentation_s1_page_3\n",
      "      Type: press_release | Quarter: Q3 | Chunk Length: 3522 characters\n",
      "      Data: Meta Reports Third  Quarter 2025  Results\n",
      "MENLO PARK, Calif. â€“ October 29, 2025  â€“ Meta Platforms, I\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 4 on Strategy 1 - ByPage Index\n",
      "     Title: Specific Speaker Question\n",
      "     Question: What did Susan Li say about European regulatory headwinds and DMA compliance in the earnings calls?\n",
      "\n",
      "   Retrieved 82 relevant chunks from ByPage Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Susan Li discussed the European regulatory headwinds and DMA compliance during Meta's earnings calls. She mentioned that the European Commission determined that Meta's subscription model for no ads is not compliant with the Digital Markets Act (DMA). As a result, Meta expects to need to make modifications to its model, which could significantly impact the user experience for European users and have a significant impact on Meta's European business and revenue. These changes could take effect as early as the third quarter of 2025, even though Meta plans to appeal the decision (Chunk 5).\n",
      "\n",
      "   Top 3 Retrieved Chunks of 82:\n",
      "   => Chunk ID: Q1_followup_qa_s1_page_1\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 3120 characters\n",
      "      Data: 1 \n",
      " Meta Platforms , Inc. ( META ) \n",
      "First Quarter 202 5 Results Conference Call  \n",
      "April 30th, 202 5 \n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s1_page_2\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 2266 characters\n",
      "      Data: 4 \n",
      " More broadly, this has been a good start to what I expect will continue to be an intense year. \n",
      "\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s1_page_3\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 2952 characters\n",
      "      Data: 5 \n",
      " Our community across the Family of Apps continues to grow, and we estimate more than 3.4 \n",
      "billio\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 5 on Strategy 1 - ByPage Index\n",
      "     Title: Technical Detail Question\n",
      "     Question: How does Meta's GEM (Generative Ads Recommendation model) work and what improvements did it deliver?\n",
      "\n",
      "   Retrieved 85 relevant chunks from ByPage Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's Generative Ads Recommendation model (GEM) works by using a new architecture that is twice as efficient at improving ad performance for a given amount of data and compute. This increased efficiency allows Meta to significantly scale up the compute used for model training, utilizing thousands of GPUs in their largest cluster for ads training to date. The model was first tested for ads recommendations on Facebook Reels, resulting in up to a 5% increase in ad conversions. Following this success, the model is being rolled out to additional surfaces across Meta's apps. \n",
      "\n",
      "The improvements delivered by GEM include a significant increase in conversion rates and a notable enhancement in ad performance, which in turn has helped optimize the ads ranking and recommendations performance across Meta's platforms. This development is part of Meta's broader strategy to improve advertising efficiency and effectiveness, contributing to strong year-over-year growth in ad revenue and overall performance gains.\n",
      "\n",
      "Cited Chunks: [Chunk 6], [Chunk 10]\n",
      "\n",
      "   Top 3 Retrieved Chunks of 85:\n",
      "   => Chunk ID: Q1_followup_qa_s1_page_1\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 3120 characters\n",
      "      Data: 1 \n",
      " Meta Platforms , Inc. ( META ) \n",
      "First Quarter 202 5 Results Conference Call  \n",
      "April 30th, 202 5 \n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s1_page_2\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 3632 characters\n",
      "      Data: 2 \n",
      " In just the last quarter, we're testing a new ads recommendation model for Reels, which has \n",
      "alr\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s1_page_3\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 3686 characters\n",
      "      Data: 3 \n",
      " that we're all going to have an AI that we talk to throughout the day -- while we're browsing \n",
      "c\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 6 on Strategy 1 - ByPage Index\n",
      "     Title: Future Guidance Question\n",
      "     Question: What is Meta's guidance for Q4 2025 revenue and capital expenditures?\n",
      "\n",
      "   Retrieved 39 relevant chunks from ByPage Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "I don't have enough information to answer this question. The provided document chunks do not specify Meta's guidance for Q4 2025 revenue and capital expenditures.\n",
      "\n",
      "   Top 3 Retrieved Chunks of 39:\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 1768 characters\n",
      "      Data: CFO Outlook Commentary\n",
      "We expect second quarter 2025 total revenue to be in the range of $ 42.5-45.5\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_2\n",
      "      Type: press_release | Quarter: Q2 | Chunk Length: 3280 characters\n",
      "      Data: CFO Outlook Commentary\n",
      "We expect third quarter 2025 total revenue to be in the range of $ 47.5-50.5 \n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_3\n",
      "      Type: press_release | Quarter: Q3 | Chunk Length: 3543 characters\n",
      "      Data: CFO Outlook Commentary\n",
      "We expect fourth quarter 2025 total revenue to be in the range of $ 56-59 bil\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Execute propmts on Strategy 1 - ByPage Index\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ EXECUTING RAG PROMPTS ON STRATEGY 1 - BY PAGE INDEX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s1_index_results = []\n",
    "for prompt in rag_prompts:\n",
    "    print(f\"\\nğŸ” Executing Prompt {prompt['id']} on Strategy 1 - ByPage Index\")\n",
    "    print(f\"     Title: {prompt['title']}\")\n",
    "    print(f\"     Question: {prompt['query']}\")\n",
    "    \n",
    "    # Query the collection for relevant chunks based on doc_type and keywords\n",
    "    retrieved_docs = []\n",
    "    retrieved_metadata = []\n",
    "    for doc_type in prompt['doc_types']:\n",
    "        results = query_collection(s1_bypage_collection, doc_type=doc_type)\n",
    "        for doc, meta in zip(results['documents'], results['metadatas']):\n",
    "            if any(keyword.lower() in doc.lower() for keyword in prompt['search_keywords']):\n",
    "                retrieved_docs.append(doc)\n",
    "                retrieved_metadata.append(meta)\n",
    "                \n",
    "    \n",
    "    print(f\"\\n   Retrieved {len(retrieved_docs)} relevant chunks from ByPage Index\")\n",
    "    \n",
    "    # Generate answer using GPT-4o\n",
    "    answer = generate_rag_answer(prompt['query'], retrieved_docs)\n",
    "    s1_index_results.append({\n",
    "        \"prompt_id\": prompt['id'],\n",
    "        \"question\": prompt['query'],\n",
    "        \"answer\": answer,\n",
    "        \"retrieved_chunks\": len(retrieved_docs)\n",
    "    })\n",
    "    \n",
    "    print(f\"ğŸ’¬ Generated Answer:\\n{answer}\")\n",
    "    \n",
    "    print(f\"\\n   Top 3 Retrieved Chunks of {len(retrieved_docs)}:\")\n",
    "    for i, chunk in enumerate(retrieved_docs[:3]):\n",
    "        print(f\"   => Chunk ID: {results['ids'][i]}\")\n",
    "        print(f\"      Type: {retrieved_metadata[i]['doc_type']} | Quarter: {retrieved_metadata[i]['quarter']} | Chunk Length: {retrieved_metadata[i]['chunk_length']} characters\")\n",
    "        print(f\"      Data: {chunk[:100]}\\n\")\n",
    "    print(\"-\" * 70)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4863a3",
   "metadata": {},
   "source": [
    "### Strategy 2 - By Sentences (3)\n",
    "\n",
    "N-sentence windowing approach (n=3) for consistent chunk granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eec6e9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ EXECUTING RAG PROMPTS ON STRATEGY 2 - BY SENTENCES INDEX\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Executing Prompt 1 on Strategy 2 - BySentences Index\n",
      "     Title: Simple Fact Question\n",
      "     Question: What was Meta's total revenue in Q2 2025?\n",
      "\n",
      "   Retrieved 56 relevant chunks from BySentences Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's total revenue in Q2 2025 was $47,516 million. [Chunk 14]\n",
      "\n",
      "   Top 3 Retrieved Chunks of 56:\n",
      "   => Chunk ID: Q1_press_release_s2_sentences_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 717 characters\n",
      "      Data: \"We've had a strong start to an important year, our community continues to grow and our business is \n",
      "\n",
      "   => Chunk ID: Q1_press_release_s2_sentences_2\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 208 characters\n",
      "      Data: â€¢Ad impressions â€“ Ad impressions delivered across our Family of Apps increased  by 5% year-over-year\n",
      "\n",
      "   => Chunk ID: Q1_press_release_s2_sentences_3\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 183 characters\n",
      "      Data: 31 billion , an increase of 16% year-over-year. Revenue on a constant currency basis \n",
      "would have inc\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 2 on Strategy 2 - BySentences Index\n",
      "     Title: Long Explanation Question\n",
      "     Question: Explain Mark Zuckerberg's five major AI opportunities and how they relate to Meta's business strategy.\n",
      "\n",
      "   Retrieved 37 relevant chunks from BySentences Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "I don't have enough information to answer this question.\n",
      "\n",
      "   Top 3 Retrieved Chunks of 37:\n",
      "   => Chunk ID: Q1_earnings_call_s2_sentences_1\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 377 characters\n",
      "      Data: Joining me today to discuss our results are Mark Zuckerberg, CEO and Susan Li, CFO. Our remarks toda\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s2_sentences_2\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 159 characters\n",
      "      Data: And now, Iâ€™d like to turn the call over to Mark. Mark Zuckerberg, CEO  \n",
      " \n",
      "Thanks Ken , thanks everyo\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s2_sentences_3\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 143 characters\n",
      "      Data: S. traction there and the types of recurring user \n",
      "behaviors that youâ€™re seeing in the early Meta AI\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 3 on Strategy 2 - BySentences Index\n",
      "     Title: Comparison Question\n",
      "     Question: Compare Meta's operating margin across Q1, Q2, Q3, and Q4 2025. Which quarter had the highest margin and why?\n",
      "\n",
      "   Retrieved 39 relevant chunks from BySentences Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Based on the provided document chunks, Meta's operating margins for the quarters of 2025 are as follows:\n",
      "\n",
      "- Q1 2025: 41% (Chunk 1)\n",
      "- Q2 2025: 43% (Chunk 2)\n",
      "- Q3 2025: 40% (Chunk 3)\n",
      "- Q4 2025: 41% (Chunk 4)\n",
      "\n",
      "The highest operating margin was in Q2 2025 at 43%. This increase could be attributed to higher revenue growth and a relatively smaller increase in costs and expenses compared to other quarters, leading to improved income from operations (Chunk 2).\n",
      "\n",
      "   Top 3 Retrieved Chunks of 39:\n",
      "   => Chunk ID: Q1_presentation_s2_sentences_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 717 characters\n",
      "      Data: \"We've had a strong start to an important year, our community continues to grow and our business is \n",
      "\n",
      "   => Chunk ID: Q1_presentation_s2_sentences_2\n",
      "      Type: press_release | Quarter: Q2 | Chunk Length: 642 characters\n",
      "      Data: \"We've had a strong quarter both in terms of our business and community,\" said Mark Zuckerberg, Meta\n",
      "\n",
      "   => Chunk ID: Q1_presentation_s2_sentences_3\n",
      "      Type: press_release | Quarter: Q3 | Chunk Length: 581 characters\n",
      "      Data: \"\n",
      "Third Quarter 2025  Financial Highlights\n",
      "Three Months Ended September 30,\n",
      " % Change In millions, e\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 4 on Strategy 2 - BySentences Index\n",
      "     Title: Specific Speaker Question\n",
      "     Question: What did Susan Li say about European regulatory headwinds and DMA compliance in the earnings calls?\n",
      "\n",
      "   Retrieved 106 relevant chunks from BySentences Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Susan Li mentioned that the European Commission announced that their subscription model without ads is not compliant with the Digital Markets Act (DMA). They expect modifications to the model might be required, potentially impacting the user experience and their business and revenue in Europe by the third quarter of 2025. They plan to appeal the decision, but modifications may occur during the appeal process. She also mentioned that advertising revenue in the European Economic Area and Switzerland represented 16% of their worldwide total revenue in 2024. They are engaging with the European Commission for more clarity. [Chunks 5, 14]\n",
      "\n",
      "   Top 3 Retrieved Chunks of 106:\n",
      "   => Chunk ID: Q1_followup_qa_s2_sentences_1\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 377 characters\n",
      "      Data: Joining me today to discuss our results are Mark Zuckerberg, CEO and Susan Li, CFO. Our remarks toda\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s2_sentences_2\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 182 characters\n",
      "      Data: As always, thank you for being on this journey with us , and now, hereâ€™s Susan. Susan Li , CFO  \n",
      " \n",
      "T\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s2_sentences_3\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 272 characters\n",
      "      Data: Within ad revenue, the online commerce vertical was the largest contributor to year -over -year \n",
      "gro\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 5 on Strategy 2 - BySentences Index\n",
      "     Title: Technical Detail Question\n",
      "     Question: How does Meta's GEM (Generative Ads Recommendation model) work and what improvements did it deliver?\n",
      "\n",
      "   Retrieved 183 relevant chunks from BySentences Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's GEM (Generative Ads Recommendation model) works by using a new architecture that is twice as efficient at improving ad performance for a given amount of data and compute. This efficiency gain allowed Meta to significantly scale up the compute used for model training, with GEM being trained on thousands of GPUs, their largest cluster for ads training to date. The improvements delivered by GEM include a reported increase of up to 5% in ad conversions when tested on Facebook Reels. \n",
      "\n",
      "[Cited: Chunk 13, Chunk 14]\n",
      "\n",
      "   Top 3 Retrieved Chunks of 183:\n",
      "   => Chunk ID: Q1_followup_qa_s2_sentences_1\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 501 characters\n",
      "      Data: The major theme right now of course is how AI is transforming everything we do. A nd a s we \n",
      "continu\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s2_sentences_2\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 287 characters\n",
      "      Data: 2 \n",
      " In just the last quarter, we're testing a new ads recommendation model for Reels, which has \n",
      "alr\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s2_sentences_3\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 529 characters\n",
      "      Data: There is actually so much business through \n",
      "messaging that those countries are both in our top 10 or\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 6 on Strategy 2 - BySentences Index\n",
      "     Title: Future Guidance Question\n",
      "     Question: What is Meta's guidance for Q4 2025 revenue and capital expenditures?\n",
      "\n",
      "   Retrieved 95 relevant chunks from BySentences Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's guidance for Q4 2025 revenue is expected to be in the range of $56-59 billion. The capital expenditures for the full year 2025 are expected to be in the range of $70-72 billion, which is an increase from the prior outlook of $66-72 billion. \n",
      "\n",
      "This information is based on the details from [Chunk 7] and [Chunk 8].\n",
      "\n",
      "   Top 3 Retrieved Chunks of 95:\n",
      "   => Chunk ID: Q1_earnings_call_s2_sentences_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 343 characters\n",
      "      Data: ____________________________________\n",
      "(1) For more information on our free cash flow non-GAAP financi\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s2_sentences_2\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 288 characters\n",
      "      Data: 5 billion. Our guidance assumes foreign currency \n",
      "is an approximately 1% tailwind to year-over-year \n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s2_sentences_3\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 480 characters\n",
      "      Data: We anticipate our full year 2025 capital expenditures, including principal payments on finance lease\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Execute prompts on Strategy 2 - BySentences Index\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ EXECUTING RAG PROMPTS ON STRATEGY 2 - BY SENTENCES INDEX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s2_index_results = []\n",
    "for prompt in rag_prompts:\n",
    "    print(f\"\\nğŸ” Executing Prompt {prompt['id']} on Strategy 2 - BySentences Index\")\n",
    "    print(f\"     Title: {prompt['title']}\")\n",
    "    print(f\"     Question: {prompt['query']}\")\n",
    "    \n",
    "    # Query the collection for relevant chunks based on doc_type and keywords\n",
    "    retrieved_docs = []\n",
    "    retrieved_metadata = []\n",
    "    for doc_type in prompt['doc_types']:\n",
    "        results = query_collection(s2_bysentences_collection, doc_type=doc_type)\n",
    "        for doc, meta in zip(results['documents'], results['metadatas']):\n",
    "            if any(keyword.lower() in doc.lower() for keyword in prompt['search_keywords']):\n",
    "                retrieved_docs.append(doc)\n",
    "                retrieved_metadata.append(meta)\n",
    "                \n",
    "    \n",
    "    print(f\"\\n   Retrieved {len(retrieved_docs)} relevant chunks from BySentences Index\")\n",
    "    \n",
    "    # Generate answer using GPT-4o\n",
    "    answer = generate_rag_answer(prompt['query'], retrieved_docs)\n",
    "    s2_index_results.append({\n",
    "        \"prompt_id\": prompt['id'],\n",
    "        \"question\": prompt['query'],\n",
    "        \"answer\": answer,\n",
    "        \"retrieved_chunks\": len(retrieved_docs)\n",
    "    })\n",
    "    \n",
    "    print(f\"ğŸ’¬ Generated Answer:\\n{answer}\")\n",
    "    \n",
    "    print(f\"\\n   Top 3 Retrieved Chunks of {len(retrieved_docs)}:\")\n",
    "    for i, chunk in enumerate(retrieved_docs[:3]):\n",
    "        print(f\"   => Chunk ID: {results['ids'][i]}\")\n",
    "        print(f\"      Type: {retrieved_metadata[i]['doc_type']} | Quarter: {retrieved_metadata[i]['quarter']} | Chunk Length: {retrieved_metadata[i]['chunk_length']} characters\")\n",
    "        print(f\"      Data: {chunk[:100]}\\n\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cbf47",
   "metadata": {},
   "source": [
    "### Strategy 3 - By Sections\n",
    "\n",
    "Typography-based segmentation using font properties as hierarchical markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14145af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ EXECUTING RAG PROMPTS ON STRATEGY 3 - BY SECTIONS INDEX\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Executing Prompt 1 on Strategy 3 - BySections Index\n",
      "     Title: Simple Fact Question\n",
      "     Question: What was Meta's total revenue in Q2 2025?\n",
      "\n",
      "   Retrieved 41 relevant chunks from BySections Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's total revenue in Q2 2025 was $42,314 million. [Chunk 1]\n",
      "\n",
      "   Top 3 Retrieved Chunks of 41:\n",
      "   => Chunk ID: Q1_press_release_s3_section_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 305 characters\n",
      "      Data: Revenue\n",
      "$\n",
      "42,314 $\n",
      "36,455\n",
      "16 %\n",
      "Costs and expenses\n",
      "\n",
      "24,759\n",
      "22,637\n",
      "9 %\n",
      "Income from operations\n",
      "$\n",
      "17,555\n",
      "\n",
      "   => Chunk ID: Q1_press_release_s3_section_2\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 1731 characters\n",
      "      Data: We expect second quarter 2025 total revenue to be in the range of $42.5-45.5 billion. Our guidance a\n",
      "\n",
      "   => Chunk ID: Q1_press_release_s3_section_3\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 2613 characters\n",
      "      Data: This press release contains forward-looking statements regarding our future business plans and expec\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 2 on Strategy 3 - BySections Index\n",
      "     Title: Long Explanation Question\n",
      "     Question: Explain Mark Zuckerberg's five major AI opportunities and how they relate to Meta's business strategy.\n",
      "\n",
      "   Retrieved 24 relevant chunks from BySections Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Mark Zuckerberg outlined five major AI opportunities for Meta, which are integral to its business strategy:\n",
      "\n",
      "1. **Improved Advertising**: Meta aims to revolutionize advertising by using AI to automate the process of targeting and ad creation, allowing businesses to simply state their objectives and budget. AI will handle the rest, potentially increasing the global GDP share of advertising (Chunk 1).\n",
      "\n",
      "2. **More Engaging Experiences**: AI is being used to enhance user engagement across Meta's platforms, such as through improved content recommendations and personalized interactions (Chunk 12).\n",
      "\n",
      "3. **Business Messaging**: AI is being integrated into Meta's messaging services like WhatsApp to create more personalized and efficient communication tools, which can help businesses save time and focus on meaningful interactions (Chunk 6).\n",
      "\n",
      "4. **Meta AI**: This involves developing AI models to improve user engagement and interaction. Meta is also working on a standalone Meta AI app to reach users who prefer a more robust feature set than what's available in current apps like WhatsApp (Chunks 3, 11).\n",
      "\n",
      "5. **AI Devices**: Meta is investing in AI-integrated devices like smart glasses, which are seen as the future of personal computing, potentially replacing smartphones. These devices are designed to provide users with a constant AI assistant that enhances daily activities (Chunk 15).\n",
      "\n",
      "These initiatives reflect Meta's strategy to leverage AI to enhance its core offerings, improve user engagement, and open new revenue streams, ensuring the company stays at the forefront of technological and business innovation.\n",
      "\n",
      "(Chunks used: 1, 3, 6, 11, 12, 15)\n",
      "\n",
      "   Top 3 Retrieved Chunks of 24:\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_1\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 3120 characters\n",
      "      Data: 1 \n",
      " Meta Platforms , Inc. ( META ) \n",
      "First Quarter 202 5 Results Conference Call  \n",
      "April 30th, 202 5 \n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_2\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 2912 characters\n",
      "      Data: 9 \n",
      " ads model is not compliant with the DMA. Based on feedback from the European Commission in \n",
      "conn\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_3\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 2584 characters\n",
      "      Data: 11 \n",
      "  \n",
      " Most of that, WhatsApp engagement is in one -on-one threads, followed by \n",
      "Facebook, which is\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 3 on Strategy 3 - BySections Index\n",
      "     Title: Comparison Question\n",
      "     Question: Compare Meta's operating margin across Q1, Q2, Q3, and Q4 2025. Which quarter had the highest margin and why?\n",
      "\n",
      "   Retrieved 64 relevant chunks from BySections Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Based on the provided document chunks, here are the operating margins for Meta across the quarters of 2025:\n",
      "\n",
      "- **Q1 2025**: Operating margin was 41% (Chunk 1).\n",
      "- **Q2 2025**: Operating margin was 43% (Chunk 2).\n",
      "- **Q3 2025**: Operating margin was 40% (Chunk 3).\n",
      "- **Q4 2025**: Operating margin was 48% (Chunk 4).\n",
      "\n",
      "The highest operating margin was in **Q4 2025**, with a margin of 48%. The document does not provide specific reasons for the higher margin in Q4, but such increases can often be attributed to seasonal revenue increases, cost management, or strategic business adjustments.\n",
      "\n",
      "**Sources:**\n",
      "- Chunk 1\n",
      "- Chunk 2\n",
      "- Chunk 3\n",
      "- Chunk 4\n",
      "\n",
      "   Top 3 Retrieved Chunks of 64:\n",
      "   => Chunk ID: Q1_presentation_s1_page_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 305 characters\n",
      "      Data: Revenue\n",
      "$\n",
      "42,314 $\n",
      "36,455\n",
      "16 %\n",
      "Costs and expenses\n",
      "\n",
      "24,759\n",
      "22,637\n",
      "9 %\n",
      "Income from operations\n",
      "$\n",
      "17,555\n",
      "\n",
      "   => Chunk ID: Q1_presentation_s1_page_2\n",
      "      Type: press_release | Quarter: Q2 | Chunk Length: 306 characters\n",
      "      Data: Revenue\n",
      "$\n",
      "47,516 $\n",
      "39,071\n",
      "22 %\n",
      "Costs and expenses\n",
      "\n",
      "27,075\n",
      "24,224\n",
      "12 %\n",
      "Income from operations\n",
      "$\n",
      "20,44\n",
      "\n",
      "   => Chunk ID: Q1_presentation_s1_page_3\n",
      "      Type: press_release | Quarter: Q3 | Chunk Length: 311 characters\n",
      "      Data: Revenue\n",
      "$\n",
      "51,242 $\n",
      "40,589\n",
      "26 %\n",
      "Costs and expenses\n",
      "\n",
      "30,707\n",
      "23,239\n",
      "32 %\n",
      "Income from operations\n",
      "$\n",
      "20,53\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 4 on Strategy 3 - BySections Index\n",
      "     Title: Specific Speaker Question\n",
      "     Question: What did Susan Li say about European regulatory headwinds and DMA compliance in the earnings calls?\n",
      "\n",
      "   Retrieved 70 relevant chunks from BySections Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Susan Li acknowledged the legal and regulatory headwinds in the EU, including the decision by the European Commission that Meta's subscription for no ads model is not compliant with the Digital Markets Act (DMA). She noted that modifications to Meta's model might be necessary, which could lead to a worse user experience for European users and significantly impact Meta's European business and revenue as early as the third quarter of 2025. Meta plans to appeal the Commission's DMA decision, although changes may be enforced before or during the appeal process (Chunk 5).\n",
      "\n",
      "   Top 3 Retrieved Chunks of 70:\n",
      "   => Chunk ID: Q1_followup_qa_s3_section_82\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 3120 characters\n",
      "      Data: 1 \n",
      " Meta Platforms , Inc. ( META ) \n",
      "First Quarter 202 5 Results Conference Call  \n",
      "April 30th, 202 5 \n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s3_section_83\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 2266 characters\n",
      "      Data: 4 \n",
      " More broadly, this has been a good start to what I expect will continue to be an intense year. \n",
      "\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s3_section_84\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 2952 characters\n",
      "      Data: 5 \n",
      " Our community across the Family of Apps continues to grow, and we estimate more than 3.4 \n",
      "billio\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 5 on Strategy 3 - BySections Index\n",
      "     Title: Technical Detail Question\n",
      "     Question: How does Meta's GEM (Generative Ads Recommendation model) work and what improvements did it deliver?\n",
      "\n",
      "   Retrieved 70 relevant chunks from BySections Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's Generative Ads Recommendation model, or GEM, is a new architecture developed by Meta to improve ad performance. It is twice as efficient at improving ad performance for a given amount of data and compute compared to previous models. This efficiency gain enabled Meta to significantly scale up the amount of compute used for model training. GEM is trained on thousands of GPUs, making it Meta's largest cluster for ads training to date. The model was initially tested on Facebook Reels and delivered up to a 5% increase in ad conversions. Subsequently, it has been rolled out to additional surfaces across Meta's apps (Chunk 6).\n",
      "\n",
      "The improvements delivered by GEM include increased efficiency in ad performance and increased conversion rates by up to 5%. This has contributed to improved ad performance and higher conversion rates, supporting Meta's overall business objectives (Chunk 6).\n",
      "\n",
      "   Top 3 Retrieved Chunks of 70:\n",
      "   => Chunk ID: Q1_followup_qa_s3_section_82\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 3120 characters\n",
      "      Data: 1 \n",
      " Meta Platforms , Inc. ( META ) \n",
      "First Quarter 202 5 Results Conference Call  \n",
      "April 30th, 202 5 \n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s3_section_83\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 3632 characters\n",
      "      Data: 2 \n",
      " In just the last quarter, we're testing a new ads recommendation model for Reels, which has \n",
      "alr\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s3_section_84\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 3686 characters\n",
      "      Data: 3 \n",
      " that we're all going to have an AI that we talk to throughout the day -- while we're browsing \n",
      "c\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 6 on Strategy 3 - BySections Index\n",
      "     Title: Future Guidance Question\n",
      "     Question: What is Meta's guidance for Q4 2025 revenue and capital expenditures?\n",
      "\n",
      "   Retrieved 28 relevant chunks from BySections Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's guidance for Q4 2025 total revenue is expected to be in the range of $56-59 billion. For capital expenditures in 2025, including principal payments on finance leases, they are expected to be in the range of $70-72 billion, increased from the prior outlook of $66-72 billion. [Chunk 3]\n",
      "\n",
      "   Top 3 Retrieved Chunks of 28:\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 1731 characters\n",
      "      Data: We expect second quarter 2025 total revenue to be in the range of $42.5-45.5 billion. Our guidance a\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_2\n",
      "      Type: press_release | Quarter: Q2 | Chunk Length: 3234 characters\n",
      "      Data: We expect third quarter 2025 total revenue to be in the range of $47.5-50.5 billion. Our guidance as\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s1_page_3\n",
      "      Type: press_release | Quarter: Q3 | Chunk Length: 3492 characters\n",
      "      Data: We expect fourth quarter 2025 total revenue to be in the range of $56-59 billion. Our guidance assum\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Execute prompts on Strategy 3 - BySections Index\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ EXECUTING RAG PROMPTS ON STRATEGY 3 - BY SECTIONS INDEX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s3_index_results = []\n",
    "for prompt in rag_prompts: \n",
    "    print(f\"\\nğŸ” Executing Prompt {prompt['id']} on Strategy 3 - BySections Index\")\n",
    "    print(f\"     Title: {prompt['title']}\")\n",
    "    print(f\"     Question: {prompt['query']}\")\n",
    "    \n",
    "    # Query the collection for relevant chunks based on doc_type and keywords\n",
    "    retrieved_docs = []\n",
    "    retrieved_metadata = []\n",
    "    for doc_type in prompt['doc_types']:\n",
    "        results = query_collection(s3_bysections_collection, doc_type=doc_type)\n",
    "        for doc, meta in zip(results['documents'], results['metadatas']):\n",
    "            if any(keyword.lower() in doc.lower() for keyword in prompt['search_keywords']):\n",
    "                retrieved_docs.append(doc)\n",
    "                retrieved_metadata.append(meta)\n",
    "                \n",
    "    \n",
    "    print(f\"\\n   Retrieved {len(retrieved_docs)} relevant chunks from BySections Index\")\n",
    "    \n",
    "    # Generate answer using GPT-4o\n",
    "    answer = generate_rag_answer(prompt['query'], retrieved_docs)\n",
    "    s3_index_results.append({\n",
    "        \"prompt_id\": prompt['id'],\n",
    "        \"question\": prompt['query'],\n",
    "        \"answer\": answer,\n",
    "        \"retrieved_chunks\": len(retrieved_docs)\n",
    "    })\n",
    "    \n",
    "    print(f\"ğŸ’¬ Generated Answer:\\n{answer}\")\n",
    "    \n",
    "    print(f\"\\n   Top 3 Retrieved Chunks of {len(retrieved_docs)}:\")\n",
    "    for i, chunk in enumerate(retrieved_docs[:3]):\n",
    "        print(f\"   => Chunk ID: {results['ids'][i]}\")\n",
    "        print(f\"      Type: {retrieved_metadata[i]['doc_type']} | Quarter: {retrieved_metadata[i]['quarter']} | Chunk Length: {retrieved_metadata[i]['chunk_length']} characters\")\n",
    "        print(f\"      Data: {chunk[:100]}\\n\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890f166",
   "metadata": {},
   "source": [
    "### Strategy 4 - Fixed Token Length\n",
    "\n",
    "Token-count-based chunking with configurable size and overlap windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cecdbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ EXECUTING RAG PROMPTS ON STRATEGY 4 - FIXED TOKEN INDEX\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Executing Prompt 1 on Strategy 4 - Fixed Token Index\n",
      "     Title: Simple Fact Question\n",
      "     Question: What was Meta's total revenue in Q2 2025?\n",
      "\n",
      "   Retrieved 89 relevant chunks from Fixed Token Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "I don't have enough information to answer this question. The document chunks do not provide Meta's total revenue for Q2 2025; they only mention the expected revenue range for that quarter.\n",
      "\n",
      "   Top 3 Retrieved Chunks of 89:\n",
      "   => Chunk ID: Q1_press_release_s4_fixedtoken_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: which now has \n",
      "almost 1 billion monthly actives.\"\n",
      "First Quarter 2025  Financial Highlights\n",
      "Three Mon\n",
      "\n",
      "   => Chunk ID: Q1_press_release_s4_fixedtoken_2\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data:  %  13 %\n",
      "Net income $ 16,644 $ 12,369  35 %\n",
      "Diluted earnings per share (EPS) $ 6.43 $ 4.71  37 %\n",
      "Fir\n",
      "\n",
      "   => Chunk ID: Q1_press_release_s4_fixedtoken_3\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: erage price per ad increased  by 10% year-over-year.\n",
      "â€¢Revenue â€“ Revenue was $42.31 billion , an incr\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 2 on Strategy 4 - Fixed Token Index\n",
      "     Title: Long Explanation Question\n",
      "     Question: Explain Mark Zuckerberg's five major AI opportunities and how they relate to Meta's business strategy.\n",
      "\n",
      "   Retrieved 45 relevant chunks from Fixed Token Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "I don't have enough information to answer this question.\n",
      "\n",
      "   Top 3 Retrieved Chunks of 45:\n",
      "   => Chunk ID: Q1_earnings_call_s4_fixedtoken_86\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: 1 \n",
      " Meta Platforms , Inc. ( META ) \n",
      "First Quarter 202 5 Results Conference Call  \n",
      "April 30th, 202 5 \n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s4_fixedtoken_87\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: â€GAAP measures is included in todayâ€™s earnings press release.  The \n",
      "earnings press release and an ac\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s4_fixedtoken_88\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: â€™re seeing U.S. traction there and the types of recurring user \n",
      "behaviors that youâ€™re seeing in the \n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 3 on Strategy 4 - Fixed Token Index\n",
      "     Title: Comparison Question\n",
      "     Question: Compare Meta's operating margin across Q1, Q2, Q3, and Q4 2025. Which quarter had the highest margin and why?\n",
      "\n",
      "   Retrieved 71 relevant chunks from Fixed Token Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Based on the provided document chunks, the operating margins for Meta across the quarters of 2025 are as follows:\n",
      "\n",
      "- **Q1 2025:** 41% (Chunk 1)\n",
      "- **Q2 2025:** 43% (Chunk 2)\n",
      "- **Q3 2025:** 40% (Chunk 3)\n",
      "- **Q4 2025:** 41% (Chunk 4)\n",
      "\n",
      "The highest operating margin was in **Q2 2025** at 43%. This was due to a combination of increased revenue growth by 22% compared to Q2 2024 and a relatively smaller increase in costs and expenses by 12%, leading to a significant increase in income from operations by 38% (Chunk 2).\n",
      "\n",
      "   Top 3 Retrieved Chunks of 71:\n",
      "   => Chunk ID: Q1_presentation_s4_fixedtoken_43\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: which now has \n",
      "almost 1 billion monthly actives.\"\n",
      "First Quarter 2025  Financial Highlights\n",
      "Three Mon\n",
      "\n",
      "   => Chunk ID: Q1_presentation_s4_fixedtoken_44\n",
      "      Type: press_release | Quarter: Q2 | Chunk Length: 512 characters\n",
      "      Data: ial Highlights\n",
      "Three Months Ended June 30,\n",
      " % Change In millions, except percentages and per share a\n",
      "\n",
      "   => Chunk ID: Q1_presentation_s4_fixedtoken_45\n",
      "      Type: press_release | Quarter: Q3 | Chunk Length: 512 characters\n",
      "      Data: e deliver even a fraction of the \n",
      "opportunity ahead, then the next few years will be the most exciti\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 4 on Strategy 4 - Fixed Token Index\n",
      "     Title: Specific Speaker Question\n",
      "     Question: What did Susan Li say about European regulatory headwinds and DMA compliance in the earnings calls?\n",
      "\n",
      "   Retrieved 137 relevant chunks from Fixed Token Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Susan Li mentioned that there are regulatory headwinds in the EU that could significantly impact Meta's business and financial results. The European Commission decided that Meta's subscription model without ads is not compliant with the Digital Markets Act (DMA). Meta expects to make modifications to their model based on feedback from the European Commission, which could lead to a materially worse user experience for European users and a significant impact on Meta's European business and revenue as early as the third quarter of 2025. They plan to appeal the Commission's DMA decision, but modifications might be imposed before or during the appeal process (Chunks 5 and 6).\n",
      "\n",
      "   Top 3 Retrieved Chunks of 137:\n",
      "   => Chunk ID: Q1_followup_qa_s4_fixedtoken_221\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: 1 \n",
      " Meta Platforms , Inc. ( META ) \n",
      "First Quarter 202 5 Results Conference Call  \n",
      "April 30th, 202 5 \n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s4_fixedtoken_222\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: or our industry. I'm grateful for \n",
      "everyone who is working so hard at the company to deliver all thi\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s4_fixedtoken_223\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: On a user geography basis, ad revenue growth was strongest in Rest of World and North America \n",
      "at 19\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 5 on Strategy 4 - Fixed Token Index\n",
      "     Title: Technical Detail Question\n",
      "     Question: How does Meta's GEM (Generative Ads Recommendation model) work and what improvements did it deliver?\n",
      "\n",
      "   Retrieved 219 relevant chunks from Fixed Token Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's GEM (Generative Ads Recommendation model) works by employing a new architecture developed to improve ad performance efficiently. It is twice as efficient in improving ad performance for a given amount of data and compute, which allows Meta to significantly scale up the compute used for model training. GEM is trained on thousands of GPUs, marking it as Meta's largest cluster for ads training to date. The model was tested on Facebook Reels and resulted in up to a 5% increase in ad conversions. It is now being rolled out to additional surfaces across Meta's apps [Chunks 13 and 14].\n",
      "\n",
      "   Top 3 Retrieved Chunks of 219:\n",
      "   => Chunk ID: Q1_followup_qa_s4_fixedtoken_221\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: jor opportunities that we're focused on: improved advertising, \n",
      "more engaging experiences, business \n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s4_fixedtoken_222\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: s measurable business results at \n",
      "scale. And i f we deliver on this vision, then over the coming yea\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s4_fixedtoken_223\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: se countries are both in our top 10 or 11 by revenue even though they're ranked \n",
      "in the 30s in globa\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 6 on Strategy 4 - Fixed Token Index\n",
      "     Title: Future Guidance Question\n",
      "     Question: What is Meta's guidance for Q4 2025 revenue and capital expenditures?\n",
      "\n",
      "   Retrieved 104 relevant chunks from Fixed Token Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's guidance for Q4 2025 revenue is expected to be in the range of $56-59 billion. For capital expenditures in 2025, they currently expect it to be in the range of $70-72 billion, including principal payments on finance leases. [Chunks 8, 10, 11]\n",
      "\n",
      "   Top 3 Retrieved Chunks of 104:\n",
      "   => Chunk ID: Q1_earnings_call_s4_fixedtoken_86\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: $10.33 billion .(1) \n",
      "â€¢Headcount â€“ Headcount  was 76,834  as of March 31, 2025 , an increase  of 11% \n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s4_fixedtoken_87\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: total revenue to be in the range of $ 42.5-45.5 billion. Our guidance assumes foreign currency \n",
      "is a\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s4_fixedtoken_88\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 512 characters\n",
      "      Data: yments on finance leases, will be in the range of \n",
      "$64-72 billion, increased from our prior outlook \n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Execute prompts on Strategy 4 - Fixed Token Index\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ EXECUTING RAG PROMPTS ON STRATEGY 4 - FIXED TOKEN INDEX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s4_index_results = []\n",
    "for prompt in rag_prompts:\n",
    "    print(f\"\\nğŸ” Executing Prompt {prompt['id']} on Strategy 4 - Fixed Token Index\")\n",
    "    print(f\"     Title: {prompt['title']}\")\n",
    "    print(f\"     Question: {prompt['query']}\")\n",
    "    \n",
    "    # Query the collection for relevant chunks based on doc_type and keywords\n",
    "    retrieved_docs = []\n",
    "    retrieved_metadata = []\n",
    "    for doc_type in prompt['doc_types']:\n",
    "        results = query_collection(s4_fixedtoken_collection, doc_type=doc_type)\n",
    "        for doc, meta in zip(results['documents'], results['metadatas']):\n",
    "            if any(keyword.lower() in doc.lower() for keyword in prompt['search_keywords']):\n",
    "                retrieved_docs.append(doc)\n",
    "                retrieved_metadata.append(meta)\n",
    "                \n",
    "    \n",
    "    print(f\"\\n   Retrieved {len(retrieved_docs)} relevant chunks from Fixed Token Index\")\n",
    "    \n",
    "    # Generate answer using GPT-4o\n",
    "    answer = generate_rag_answer(prompt['query'], retrieved_docs)\n",
    "    s4_index_results.append({\n",
    "        \"prompt_id\": prompt['id'],\n",
    "        \"question\": prompt['query'],\n",
    "        \"answer\": answer,\n",
    "        \"retrieved_chunks\": len(retrieved_docs)\n",
    "    })\n",
    "    \n",
    "    print(f\"ğŸ’¬ Generated Answer:\\n{answer}\")\n",
    "    \n",
    "    print(f\"\\n   Top 3 Retrieved Chunks of {len(retrieved_docs)}:\")\n",
    "    for i, chunk in enumerate(retrieved_docs[:3]):\n",
    "        print(f\"   => Chunk ID: {results['ids'][i]}\")\n",
    "        print(f\"      Type: {retrieved_metadata[i]['doc_type']} | Quarter: {retrieved_metadata[i]['quarter']} | Chunk Length: {retrieved_metadata[i]['chunk_length']} characters\")\n",
    "        print(f\"      Data: {chunk[:100]}\\n\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666432b3",
   "metadata": {},
   "source": [
    "### Strategy 5 - Semantic Chunking\n",
    "\n",
    "Embedding-similarity-based segmentation identifying topical coherence boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0212e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ EXECUTING RAG PROMPTS ON STRATEGY 5 - SEMANTIC CHUNKING\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Executing Prompt 1 on Strategy 5 - Semantic Chunking Index\n",
      "     Title: Simple Fact Question\n",
      "     Question: What was Meta's total revenue in Q2 2025?\n",
      "\n",
      "   Retrieved 25 relevant chunks from Semantic Chunking Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's total revenue in Q2 2025 was $47.516 billion. \n",
      "\n",
      "This information was found in Chunk 7.\n",
      "\n",
      "   Top 3 Retrieved Chunks of 25:\n",
      "   => Chunk ID: Q1_press_release_s5_semantic_1\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 1208 characters\n",
      "      Data: Meta Reports First Quarter 2025  Results\n",
      "MENLO PARK, Calif. â€“ April 30, 2025  â€“ Meta Platforms, Inc.\n",
      "\n",
      "   => Chunk ID: Q1_press_release_s5_semantic_2\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 2318 characters\n",
      "      Data: â€¢Average price per ad â€“ Average price per ad increased  by 10% year-over-year. â€¢Revenue â€“ Revenue wa\n",
      "\n",
      "   => Chunk ID: Q1_press_release_s5_semantic_3\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 4523 characters\n",
      "      Data: that could significantly impact our business and our financial results. The European Commission (EC)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 2 on Strategy 5 - Semantic Chunking Index\n",
      "     Title: Long Explanation Question\n",
      "     Question: Explain Mark Zuckerberg's five major AI opportunities and how they relate to Meta's business strategy.\n",
      "\n",
      "   Retrieved 36 relevant chunks from Semantic Chunking Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Mark Zuckerberg identified five major AI opportunities that align with Meta's business strategy:\n",
      "\n",
      "1. **Improved Advertising**: AI enhances efficiency and performance in Meta's ad systems, expanding AI-powered recommendation models and using more signals for better ad conversions. This is crucial for driving revenue, especially for smaller advertisers.\n",
      "\n",
      "2. **More Engaging Experiences**: AI advancements improve content recommendation systems, increasing user engagement on platforms like Facebook and Instagram. AI video editing tools and the new Edits app are also contributing to better content quality.\n",
      "\n",
      "3. **Business Messaging**: Meta is integrating business AI into ads and e-commerce, positioning AI as a crucial tool for businesses similar to email or social media accounts. This enhances Meta's business solutions offering.\n",
      "\n",
      "4. **Meta AI**: With over a billion monthly active users, Meta AI aims to deepen engagement and become the leading personal AI. Ongoing improvements in AI models drive user interaction and retention.\n",
      "\n",
      "5. **AI Devices**: Products like Ray-Ban Meta glasses and new AI glasses models are expanding Meta's hardware ecosystem. These devices are seen as the main interface for integrating AI into daily life, supporting Meta's strategy to lead in AI-driven consumer electronics.\n",
      "\n",
      "These opportunities are central to Meta's strategy of integrating AI across its services to enhance user engagement, improve business solutions, and expand into hardware, aligning with its vision of personal superintelligence and individual empowerment (Chunks 10 and 11).\n",
      "\n",
      "   Top 3 Retrieved Chunks of 36:\n",
      "   => Chunk ID: Q1_earnings_call_s5_semantic_13\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 999 characters\n",
      "      Data: 1 \n",
      " Meta Platforms , Inc. ( META ) \n",
      "First Quarter 202 5 Results Conference Call  \n",
      "April 30th, 202 5 \n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s5_semantic_14\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 159 characters\n",
      "      Data: And now, Iâ€™d like to turn the call over to Mark. Mark Zuckerberg, CEO  \n",
      " \n",
      "Thanks Ken , thanks everyo\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s5_semantic_15\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 135 characters\n",
      "      Data: Mark Zuckerberg:  Sure. I can talk about the LLMs. On the Meta AI usage, Iâ€™m not sure if we have \n",
      "mo\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 3 on Strategy 5 - Semantic Chunking Index\n",
      "     Title: Comparison Question\n",
      "     Question: Compare Meta's operating margin across Q1, Q2, Q3, and Q4 2025. Which quarter had the highest margin and why?\n",
      "\n",
      "   Retrieved 16 relevant chunks from Semantic Chunking Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Based on the provided document chunks, Meta's operating margins for each quarter of 2025 were as follows:\n",
      "\n",
      "- Q1 2025: 41% (Chunk 1)\n",
      "- Q2 2025: 43% (Chunk 2)\n",
      "- Q3 2025: 40% (Chunk 13)\n",
      "- Q4 2025: 41% (Chunk 15)\n",
      "\n",
      "The second quarter (Q2 2025) had the highest operating margin at 43%. This higher margin can be attributed to a combination of increased revenue and a relatively lower increase in costs and expenses compared to other quarters, as indicated by the financial highlights provided.\n",
      "\n",
      "   Top 3 Retrieved Chunks of 16:\n",
      "   => Chunk ID: Q1_presentation_s5_semantic_9\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 1208 characters\n",
      "      Data: Meta Reports First Quarter 2025  Results\n",
      "MENLO PARK, Calif. â€“ April 30, 2025  â€“ Meta Platforms, Inc.\n",
      "\n",
      "   => Chunk ID: Q1_presentation_s5_semantic_10\n",
      "      Type: press_release | Quarter: Q2 | Chunk Length: 1133 characters\n",
      "      Data: Meta Reports Second  Quarter 2025  Results\n",
      "MENLO PARK, Calif. â€“ July 30, 2025  â€“ Meta Platforms, Inc\n",
      "\n",
      "   => Chunk ID: Q1_presentation_s5_semantic_11\n",
      "      Type: press_release | Quarter: Q3 | Chunk Length: 1249 characters\n",
      "      Data: Meta Reports Third  Quarter 2025  Results\n",
      "MENLO PARK, Calif. â€“ October 29, 2025  â€“ Meta Platforms, I\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 4 on Strategy 5 - Semantic Chunking Index\n",
      "     Title: Specific Speaker Question\n",
      "     Question: What did Susan Li say about European regulatory headwinds and DMA compliance in the earnings calls?\n",
      "\n",
      "   Retrieved 98 relevant chunks from Semantic Chunking Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Susan Li addressed European regulatory headwinds and DMA compliance in the earnings calls by stating that the European Commission found Meta's subscription for no ads model non-compliant with the DMA. This decision may require modifications to Meta's model, which could adversely impact user experience for European users and significantly affect their business and revenue in Europe as early as the third quarter of 2025. Meta plans to appeal the decision but modifications may be required before or during the appeal process. Additionally, she mentioned that advertising revenue from the European Economic Area and Switzerland constituted 16% of Meta's worldwide total revenue in 2024. [Chunks 4, 12]\n",
      "\n",
      "   Top 3 Retrieved Chunks of 98:\n",
      "   => Chunk ID: Q1_followup_qa_s5_semantic_83\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 999 characters\n",
      "      Data: 1 \n",
      " Meta Platforms , Inc. ( META ) \n",
      "First Quarter 202 5 Results Conference Call  \n",
      "April 30th, 202 5 \n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s5_semantic_84\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 1281 characters\n",
      "      Data: All of the opportunities that I've \n",
      "discussed today are downstream of delivering general intelligenc\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s5_semantic_85\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 942 characters\n",
      "      Data: Iâ€™ll begin with our Family of Apps segment. 5 \n",
      " Our community across the Family of Apps continues to\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 5 on Strategy 5 - Semantic Chunking Index\n",
      "     Title: Technical Detail Question\n",
      "     Question: How does Meta's GEM (Generative Ads Recommendation model) work and what improvements did it deliver?\n",
      "\n",
      "   Retrieved 101 relevant chunks from Semantic Chunking Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's GEM (Generative Ads Recommendation model) is an advanced ads ranking model introduced to improve ad performance. It employs a new architecture that is twice as efficient in enhancing ad performance for a given amount of data and compute. This increased efficiency allows for a significant scale-up in compute used for model training, with GEM being trained on thousands of GPUs, constituting Meta's largest cluster for ads training to date. When tested on Facebook Reels, the model demonstrated up to a 5% increase in ad conversions, and it is in the process of being rolled out to additional surfaces across Meta's apps. (Chunk 7)\n",
      "\n",
      "   Top 3 Retrieved Chunks of 101:\n",
      "   => Chunk ID: Q1_followup_qa_s5_semantic_83\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 842 characters\n",
      "      Data: Our community keeps growing with more than 3.4 billion \n",
      "people now using at least one of our apps ea\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s5_semantic_84\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 1910 characters\n",
      "      Data: But if we do, then I think that we will be wildly happy with the \n",
      "investments  that weâ€™re making . T\n",
      "\n",
      "   => Chunk ID: Q1_followup_qa_s5_semantic_85\n",
      "      Type: earnings_call | Quarter: Q1 | Chunk Length: 1244 characters\n",
      "      Data: Right now the vast majority of our business is \n",
      "advertising in feeds on Facebook and Instagram. But \n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Executing Prompt 6 on Strategy 5 - Semantic Chunking Index\n",
      "     Title: Future Guidance Question\n",
      "     Question: What is Meta's guidance for Q4 2025 revenue and capital expenditures?\n",
      "\n",
      "   Retrieved 51 relevant chunks from Semantic Chunking Index\n",
      "ğŸ’¬ Generated Answer:\n",
      "Meta's guidance for Q4 2025 revenue is expected to be in the range of $56-59 billion. In terms of capital expenditures for the full year 2025, Meta anticipates spending in the range of $70-72 billion, with the fourth quarter's capital expenditures amounting to $22.14 billion [Chunk 3, Chunk 5].\n",
      "\n",
      "   Top 3 Retrieved Chunks of 51:\n",
      "   => Chunk ID: Q1_earnings_call_s5_semantic_13\n",
      "      Type: press_release | Quarter: Q1 | Chunk Length: 2318 characters\n",
      "      Data: â€¢Average price per ad â€“ Average price per ad increased  by 10% year-over-year. â€¢Revenue â€“ Revenue wa\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s5_semantic_14\n",
      "      Type: press_release | Quarter: Q2 | Chunk Length: 3234 characters\n",
      "      Data: â€¢Average price per ad â€“ Average price per ad increased  by 9% year-over-year. â€¢Revenue â€“ Revenue  wa\n",
      "\n",
      "   => Chunk ID: Q1_earnings_call_s5_semantic_15\n",
      "      Type: press_release | Quarter: Q3 | Chunk Length: 3083 characters\n",
      "      Data: federal deferred tax assets, reflecting the impact of the U.S. Corporate Alternative Minimum Tax. As\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Execute prompts on Strategy 5 - Semantic Chunking Index\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ EXECUTING RAG PROMPTS ON STRATEGY 5 - SEMANTIC CHUNKING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "s5_index_results = []\n",
    "for prompt in rag_prompts:\n",
    "    print(f\"\\nğŸ” Executing Prompt {prompt['id']} on Strategy 5 - Semantic Chunking Index\")\n",
    "    print(f\"     Title: {prompt['title']}\")\n",
    "    print(f\"     Question: {prompt['query']}\")\n",
    "    \n",
    "    # Query the collection for relevant chunks based on doc_type and keywords\n",
    "    retrieved_docs = []\n",
    "    retrieved_metadata = []\n",
    "    for doc_type in prompt['doc_types']:\n",
    "        results = query_collection(s5_semantic_collection, doc_type=doc_type)\n",
    "        for doc, meta in zip(results['documents'], results['metadatas']):\n",
    "            if any(keyword.lower() in doc.lower() for keyword in prompt['search_keywords']):\n",
    "                retrieved_docs.append(doc)\n",
    "                retrieved_metadata.append(meta)\n",
    "                \n",
    "    \n",
    "    print(f\"\\n   Retrieved {len(retrieved_docs)} relevant chunks from Semantic Chunking Index\")\n",
    "    \n",
    "    # Generate answer using GPT-4o\n",
    "    answer = generate_rag_answer(prompt['query'], retrieved_docs)\n",
    "    s5_index_results.append({\n",
    "        \"prompt_id\": prompt['id'],\n",
    "        \"question\": prompt['query'],\n",
    "        \"answer\": answer,\n",
    "        \"retrieved_chunks\": len(retrieved_docs)\n",
    "    })\n",
    "    \n",
    "    print(f\"ğŸ’¬ Generated Answer:\\n{answer}\")\n",
    "    \n",
    "    print(f\"\\n   Top 3 Retrieved Chunks of {len(retrieved_docs)}:\")\n",
    "    for i, chunk in enumerate(retrieved_docs[:3]):\n",
    "        print(f\"   => Chunk ID: {results['ids'][i]}\")\n",
    "        print(f\"      Type: {retrieved_metadata[i]['doc_type']} | Quarter: {retrieved_metadata[i]['quarter']} | Chunk Length: {retrieved_metadata[i]['chunk_length']} characters\")\n",
    "        print(f\"      Data: {chunk[:100]}\\n\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee1241",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f4a5d1",
   "metadata": {},
   "source": [
    "### Analysis By Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eab3e49",
   "metadata": {},
   "source": [
    "#### ğŸ“Œ Question 1: Simple Fact Question\n",
    "**\"What was Meta's total revenue in Q2 2025?\"**\n",
    "\n",
    "| Strategy | Answered? | Chunks Retrieved | Accuracy | Notes |\n",
    "|----------|----------------|------------------|----------|-------|\n",
    "| **Semantic Chunking** | Yes | 25 | **Correct** ($47.516B + YoY context) | Best - fewest chunks, most context |\n",
    "| **By Page** | Yes | 32 | **Correct** ($47.516B) | Good but retrieved more chunks |\n",
    "| **By Sentences** | Yes | 56 | **Correct** ($47,516M) | Too many chunks for simple fact |\n",
    "| **By Sections** | No | 41 | **WRONG** | \"Not enough information\" |\n",
    "| **Fixed Token** | No | 89 | **WRONG** | \"Not enough information\" |\n",
    "\n",
    "**Winner: Semantic Chunking** - Most efficient (25 chunks vs 32-89), added context (YoY growth)\n",
    "\n",
    "**Key Insight**: Fixed Token and By Sections likely split the financial table, losing critical context.\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ“Œ Question 2: Long Explanation Question\n",
    "**\"Explain Mark Zuckerberg's five major AI opportunities and business strategy\"**\n",
    "\n",
    "| Strategy | Answered? | Chunks Retrieved | Completeness | Notes |\n",
    "|----------|----------------|------------------|--------------|-------|\n",
    "| **Semantic Chunking** | Yes | 36 | **Complete** (All 5 explained + strategy) | Best Response |\n",
    "| **By Sections** | Yes | 24 | **Complete** (All 5 explained + strategy) | Fewest chunks, excellent quality |\n",
    "| **By Page** | Yes | 30 | **Complete** (All 5 explained) | Good but slightly more verbose |\n",
    "| **By Sentences** | No | 37 | **WRONG** | \"Not enough information\" |\n",
    "| **Fixed Token** | No | 45 | **WRONG** | \"Not enough information\" |\n",
    "\n",
    "**Winner: By Sections (24 chunks)** with Semantic Chunking close second (36 chunks)\n",
    "\n",
    "**Key Insight**: Long narrative needs semantic boundaries. Sentence-based chunking fragments the narrative. Fixed Token splits mid-explanation.\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ“Œ Question 3: Comparison Question\n",
    "**\"Compare operating margins Q1-Q4 2025, which was highest and why?\"**\n",
    "\n",
    "| Strategy | Answered? | Chunks Retrieved | Accuracy | Explanation Quality |\n",
    "|----------|----------------|------------------|----------|---------------------|\n",
    "| **Semantic Chunking** | Yes | 16 | **All Correct** | Clear explanation | \n",
    "| **By Page** | Yes | 64 | **All Correct** | Clear explanation |\n",
    "| **By Sections** | Yes | 64 | **Q4 wrong (42% vs 41%)** | Minor error |\n",
    "| **By Sentences** | Yes | 39 | **All Correct** | Clear explanation |\n",
    "| **Fixed Token** | Yes | 71 | **All Correct** | Good explanation |\n",
    "\n",
    "**Winner: Semantic Chunking** - Most efficient (only 16 chunks for 4-quarter comparison!)\n",
    "\n",
    "**Key Insight**: All strategies handled this well. Semantic Chunking's efficiency is remarkable - 4x fewer chunks than other options.\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ“Œ Question 4: Specific Speaker Question\n",
    "**\"What did Susan Li say about European regulatory headwinds and DMA?\"**\n",
    "\n",
    "| Strategy | Answered? | Chunks Retrieved | Accuracy | Context Preserved |\n",
    "|----------|----------------|------------------|----------|-------------------|\n",
    "| **Semantic Chunking** | Yes | 98 | **Complete** | Full context + revenue impact (16%) |\n",
    "| **By Page** | Yes | 82 | **Complete** | Good context |\n",
    "| **By Sections** | Yes | 70 | **Complete** | Good context |\n",
    "| **Fixed Token** | Yes | 137 | **Complete** | Good but too many chunks |\n",
    "| **By Sentences** | No | 106 | **ERROR** | Rate limited (429 error) |\n",
    "\n",
    "**Winner: By Sections (70 chunks)** - Most efficient while maintaining quality\n",
    "\n",
    "**Key Insight**: Sentence-based chunking retrieved too many fragments and hit rate limits. Semantic Chunking provided most comprehensive answer with extra revenue context.\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ“Œ Question 5: Technical Detail Question\n",
    "**\"How does GEM model work and what improvements did it deliver?\"**\n",
    "\n",
    "| Strategy | Answered? | Chunks Retrieved | Completeness | Technical Detail |\n",
    "|----------|----------------|------------------|--------------|------------------|\n",
    "| **Semantic Chunking** | Yes | 101 | **Complete** | Full technical explanation |\n",
    "| **By Page** | Yes | 85 | **Complete** | Full technical explanation |\n",
    "| **By Sections** | Yes | 70 | **Complete** | Full technical explanation |\n",
    "| **By Sentences** | Yes | 183 | **Partial** | Basic explanation only |\n",
    "| **Fixed Token** | No | 236 | **WRONG** | \"Not enough information\" |\n",
    "\n",
    "**Winner: By Sections (70 chunks)** - Most efficient with complete answer\n",
    "\n",
    "**Key Insight**: Fixed Token retrieved 236 chunks but still failed! Technical explanations need semantic boundaries. Sentence chunking retrieved too many fragments.\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ“Œ Question 6: Future Guidance Question\n",
    "**\"What is Meta's Q4 2025 revenue and CapEx guidance?\"**\n",
    "\n",
    "| Strategy | Answered? | Chunks Retrieved | Accuracy | Notes |\n",
    "|----------|----------------|------------------|----------|-------|\n",
    "| **Semantic Chunking** | Yes | 51 | **Correct** (Revenue + CapEx) | Complete answer |\n",
    "| **By Page** | Yes | 39 | **Correct** (Revenue + CapEx) | Most efficient |\n",
    "| **By Sections** | Yes | 28 | **Correct** (Revenue + CapEx) | Most efficient! |\n",
    "| **By Sentences** | Yes | 95 | **Correct** (Revenue + CapEx) | Too many chunks |\n",
    "| **Fixed Token** | Yes | 105 | **Correct** (Revenue + CapEx) | Too many chunks |\n",
    "\n",
    "**Winner: By Sections (28 chunks)** - Most efficient\n",
    "\n",
    "**Key Insight**: All strategies succeeded here. \"CFO Outlook\" sections are well-structured, making this easier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45d653",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2b01a",
   "metadata": {},
   "source": [
    "| Strategy | Questions Answered | Success Rate | Avg Chunks Retrieved | Comments |\n",
    "|----------|-------------------|--------------|---------------------|------------|\n",
    "| **Semantic Chunking** | 6/6 | **100%** | 54.5 | Overall Best |\n",
    "| **By Page** | 6/6 | **100%** | 55.2 | Strong Second |\n",
    "| **By Sections** | 5/6 | **83%** | 49.5 | Efficient, but risky based on document type |\n",
    "| **By Sentences** | 5/6 | **83%** | 86.0 | Not recommended |\n",
    "| **Fixed Token** | 3/6 | **50%** | 120.8 | Poor Performance |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed6b18",
   "metadata": {},
   "source": [
    "### Key Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f09ed39",
   "metadata": {},
   "source": [
    "1. **Semantic Chunking** - Strong Option\n",
    "- 100% success rate\n",
    "- Balanced efficiency vs. accuracy trade-off\n",
    "- More complicated than other strategies considered here\n",
    "\n",
    "2. **By Page** - Safe & Simple\n",
    "- 100% success rate\n",
    "- Simple implementation\n",
    "- Good default if Semantic Chunking cannot be implemented.\n",
    "\n",
    "3. **By Section** - Has a critical flaw\n",
    "- Extremely efficient when it works\n",
    "- Fails on tables/metrics or when document is not hierarchical (presentation)\n",
    "- Need a fallback approach for some document types. Here we used ByPage strategy if we could not determine sections in the document.\n",
    "\n",
    "4. **By Sentences** - Chunking fragments too much\n",
    "- 183 chunks for the techical question\n",
    "- Caused rate limiting in some cases\n",
    "\n",
    "5. **Fixed Token Length** - False Economy\n",
    "- Retrieved most chunks compared to other strategies\n",
    "- Failed 50% of questions\n",
    "- Arbitrarily split the documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
